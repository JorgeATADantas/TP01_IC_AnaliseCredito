{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QYddtZjGH_s"
   },
   "source": [
    "**Tabalho Prático 1 – Análise de Crédito**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghA_ViPQGH3r"
   },
   "source": [
    "**Alunos:\n",
    "\n",
    "GIOVANNI SURIANI FERREIRA\n",
    "\n",
    "JORGE ALIOMAR TROCOLI ABDON DANTAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFr8QeByGHqO"
   },
   "source": [
    "**Enunciado(s):**\n",
    "\n",
    "Cada dupla deve escolher um problema no Kaggle. Elaborar uma solução e apresentar para turma no dia da entrega. A solução da dupla deve ser entregue no Moodle em um Python Notebook. Especificamente, a dupla deve:\n",
    "- Pesquisar um problema interessante no Kaggle que envolva dados tabulares/estruturados;\n",
    "- Realizar uma análise exploratória dos dados da competição. Isto é, visualizar os dados, tentar identificar dados faltantes, instâncias ruidosas e tendências nos dados;\n",
    "- Entender e implementar a métrica de avaliação da competição;\n",
    "- Implementar uma solução simples para o problema da competição para gerar um baseline (isto é, o desempenho mínimo que o sua abordagem deve alcançar);\n",
    "- Estudar soluções para problemas semelhantes ao da competição escolhida. A dupla pode pesquisar, por exemplo, em artigos acadêmicos, artigos técnicos da Internet e o no próprio Kaggle;\n",
    "- Implementar diferentes abordagens para a competição e reportar o desempenho de cada abordagem implementada;\n",
    "- Realizar uma avaliação de parâmetro (hyperparameter tuning) das abordagens escolhidas para o problema. Para realizar a avaliação dos parâmetros você pode utilizar GridSearchCV ou Optuna.\n",
    "- Além de outras abordagens, a dupla deve:\n",
    "    - Propor pelo menos uma abordagem que envolva meta-learning. Ou seja, a dupla deve propor uma forma diferente de combinar vários modelos. Por exemplo, utilize a abordagem do Random Forest, porém com vários classificadores ou invés de utilizar apenas Árvores de Decisão.\n",
    "- Para cada abordagem apresentada, a dupla deve apresentar:\n",
    "    - desempenho no conjunto de treino, o desempenho deve ser medido com uma validação cruzada com 10 folds (10-fold cross-validation).\n",
    "    - desempenho no conjunto de teste reportado pelo Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_eehgWhhN8g"
   },
   "source": [
    "# DESAFIO E PROBLEMA ESCOLHIDO\n",
    "Home Credit Default Risk (https://www.kaggle.com/competitions/home-credit-default-risk)\n",
    "\n",
    "O desafio consiste em melhorar os modelos preditivos, da HOME CREDIT, de crédito voltados a pessoas sem histórico bancário. Utilizando dados alternativos como registros de telecomunicações e transações, a empresa quer garantir que mais pessoas aptas recebam empréstimos justos e sustentáveis. O desafio propõe que os participantes usem técnicas de ciência de dados e machine learning para prever com mais precisão a capacidade de pagamento dos clientes.\n",
    "\n",
    "O conjunto de dados contém informações detalhadas sobre o histórico financeiro de clientes da Home Credit e de outras instituições, com o objetivo de prever a capacidade de pagamento de novos empréstimos.\n",
    "\n",
    " - application_{train|test}.csv: Esta é a tabela principal, dividida em dois arquivos: Treinamento (com a variável TARGET) e Teste (sem TARGET). Contém dados estáticos de todas as solicitações de empréstimo. Cada linha representa um empréstimo.\n",
    "\n",
    " - bureau.csv: Todos os créditos anteriores dos clientes fornecidos por outras instituições financeiras, reportados ao Bureau de Crédito (apenas para clientes com empréstimo na amostra). Cada linha representa um crédito anterior registrado antes da data da aplicação atual.\n",
    "\n",
    " - bureau_balance.csv: Saldos mensais dos créditos anteriores no Bureau de Crédito. Cada linha representa um mês de histórico para cada crédito anterior — ou seja, número de empréstimos * número de créditos anteriores * número de meses com histórico disponível.\n",
    "\n",
    " - POS_CASH_balance.csv: Saldos mensais dos empréstimos anteriores no ponto de venda (POS) ou empréstimos em dinheiro que o cliente teve com a Home Credit. Uma linha por mês de histórico de cada crédito anterior relacionado ao empréstimo na amostra.\n",
    "\n",
    " - credit_card_balance.csv: Saldos mensais dos cartões de crédito anteriores que o cliente tem com a Home Credit. Formato similar ao POS_CASH_balance, mas para cartões de crédito.\n",
    "\n",
    " - previous_application.csv: Todas as solicitações anteriores de empréstimos feitas à Home Credit por clientes com empréstimos na amostra atual. Uma linha por solicitação anterior.\n",
    "\n",
    " - installments_payments.csv: Histórico de pagamentos de créditos anteriores concedidos pela Home Credit. Inclui: a) uma linha para cada pagamento feito, e b) uma linha para cada parcela não paga. Cada linha representa um pagamento ou uma parcela de um crédito anterior.\n",
    "\n",
    " - HomeCredit_columns_description.csv: Arquivo com a descrição das colunas de todos os outros arquivos do conjunto de dados.\n",
    "\n",
    " As tabelas podem se relacionar conforme imagem abaixo:\n",
    "\n",
    " ![image.png](attachment:image.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzZ2MAv0hN8i"
   },
   "source": [
    "# PREPARAÇÃO DA BASE DE DADOS - Todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G3ZCBI41MkU5"
   },
   "outputs": [],
   "source": [
    "#Importando Bibliotecas Pandas e Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "\n",
    "#Otimizador Giovanni\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "\n",
    "\n",
    "#CSV_PATH = \"/home/gi/Desktop/Semestre8/Inteligencia_Computacional/TP1_csvs\" # Path Giovanni\n",
    "CSV_PATH = \"E:/Documentos/CEFET/OneDrive/Documentos/2ECOM067_INTELIGENCIA-COMPUTACIONAL-I_T01/TP1/bases/\" # Path Jorge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pGvW8rR6hN8m"
   },
   "outputs": [],
   "source": [
    "#Desabilitando os warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "232RQBEu3mWD"
   },
   "outputs": [],
   "source": [
    "#Carregando Base de dados principal - Treino\n",
    "df_train = pd.read_csv(f\"{CSV_PATH}/application_train.csv\")\n",
    "df_test  = pd.read_csv(f\"{CSV_PATH}/application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VmdSzn83hN8n"
   },
   "outputs": [],
   "source": [
    "# Como o volume de informações é muito grande, iremos ao invés de montar uma base única entre a base principal e as\n",
    "# demais tabelas auxiliares, iremos criar 8 bases (conforme descrito abaixo), realizar as devidas simulações e utilizar\n",
    "# as estratégias de emsemble.\n",
    "# Bases que serão construídas:\n",
    "#   -   df_01_train = application_train + bureau + bureau_balance\n",
    "#   -   df_01_test  = application_test  + bureau + bureau_balance\n",
    "#   -   df_02_train = application_train + previous_application + POS_CASH_balance\n",
    "#   -   df_02_test  = application_test  + previous_application + POS_CASH_balance\n",
    "#   -   df_03_train = application_train + previous_application + installments_payments\n",
    "#   -   df_03_test  = application_test  + previous_application + installments_payments\n",
    "#   -   df_04_train = application_train + previous_application + credit_card_balance\n",
    "#   -   df_04_test  = application_test  + previous_application + credit_card_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG3hzUzShN8o"
   },
   "source": [
    "## DataFrame 01 = application_train/test + bureau + bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MuJLIIy3hN8p"
   },
   "outputs": [],
   "source": [
    "#Carregamento de Bases de Dados Auxiliares\n",
    "df_auxiliar_bureau                          = pd.read_csv(f\"{CSV_PATH}/bureau.csv\")\n",
    "df_auxiliar_bureau_balance                  = pd.read_csv(f\"{CSV_PATH}/bureau_balance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SvzYkRubhN8p"
   },
   "outputs": [],
   "source": [
    "#Copia do df_train e df_test\n",
    "df_01_train = df_train.copy()\n",
    "df_01_test  = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mQbEMBqzhN8p"
   },
   "outputs": [],
   "source": [
    "#Realização do left join de df_train com df_auxiliar_bureau\n",
    "# DF da esquerda = df_train\n",
    "# DF da direita  = df_auxiliar_bureau\n",
    "df_01_train = df_01_train.join(df_auxiliar_bureau, on='SK_ID_CURR', lsuffix = ' ', how='left')\n",
    "df_01_train = df_01_train.drop(columns={\"SK_ID_CURR\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_01_train com df_auxiliar_bureau_balance\n",
    "# DF da esquerda = df_01_train\n",
    "# DF da direita  = df_auxiliar_bureau_balance\n",
    "df_01_train = df_01_train.join(df_auxiliar_bureau_balance, on='SK_ID_BUREAU', lsuffix = ' ',  how='left')\n",
    "df_01_train = df_01_train.drop(columns={\"SK_ID_BUREAU\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_test com df_auxiliar_bureau\n",
    "# DF da esquerda = df_test\n",
    "# DF da direita  = df_auxiliar_bureau\n",
    "df_01_test = df_01_test.join(df_auxiliar_bureau, on='SK_ID_CURR', lsuffix = ' ', how='left')\n",
    "df_01_test = df_01_test.drop(columns={\"SK_ID_CURR\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_01_test com df_auxiliar_bureau_balance\n",
    "# DF da esquerda = df_01_test\n",
    "# DF da direita  = df_auxiliar_bureau_balance\n",
    "df_01_test = df_01_test.join(df_auxiliar_bureau_balance, on='SK_ID_BUREAU', lsuffix = ' ',  how='left')\n",
    "df_01_test = df_01_test.drop(columns={\"SK_ID_BUREAU\"}) #Excluir coluna duplicada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORJGbE77hN8q"
   },
   "source": [
    "## DataFrame 02 = application_train/test + previous_application + POS_CASH_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "G_E1EieqhN8q"
   },
   "outputs": [],
   "source": [
    "#Carregamento de Bases de Dados Auxiliares\n",
    "df_auxiliar_previous_application            = pd.read_csv(f\"{CSV_PATH}/previous_application.csv\")\n",
    "df_auxiliar_POS_CASH_balance                = pd.read_csv(f\"{CSV_PATH}/POS_CASH_balance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6kH1FyQ9hN8q"
   },
   "outputs": [],
   "source": [
    "#Copia do df_train e df_test\n",
    "df_02_train = df_train.copy()\n",
    "df_02_test  = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wQObHn9JhN8r"
   },
   "outputs": [],
   "source": [
    "#Realização do left join de df_train com df_auxiliar_previous_application\n",
    "# DF da esquerda = df_train\n",
    "# DF da direita  = df_auxiliar_previous_application\n",
    "df_02_train = df_02_train.join(df_auxiliar_previous_application, on='SK_ID_CURR', lsuffix = ' ', how='left')\n",
    "df_02_train = df_02_train.drop(columns={\"SK_ID_CURR\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_02_train com df_auxiliar_POS_CASH_balance\n",
    "# DF da esquerda = df_02_train\n",
    "# DF da direita  = df_auxiliar_POS_CASH_balance\n",
    "df_02_train = df_02_train.join(df_auxiliar_POS_CASH_balance, on='SK_ID_PREV', lsuffix = ' ',  how='left')\n",
    "df_02_train = df_02_train.drop(columns={\"SK_ID_PREV\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_test com df_auxiliar_previous_application\n",
    "# DF da esquerda = df_test\n",
    "# DF da direita  = df_auxiliar_previous_application\n",
    "df_02_test = df_02_test.join(df_auxiliar_previous_application, on='SK_ID_CURR', lsuffix = ' ', how='left')\n",
    "df_02_test = df_02_test.drop(columns={\"SK_ID_CURR\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_02_test com df_auxiliar_POS_CASH_balance\n",
    "# DF da esquerda = df_02_test\n",
    "# DF da direita  = df_auxiliar_POS_CASH_balance\n",
    "df_02_test = df_02_test.join(df_auxiliar_POS_CASH_balance, on='SK_ID_PREV', lsuffix = ' ',  how='left')\n",
    "df_02_test = df_02_test.drop(columns={\"SK_ID_PREV\"}) #Excluir coluna duplicada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIH0nicmhN8r"
   },
   "source": [
    "## DataFrame 03 = application_train/test + previous_application + installments_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LbMuKqNVhN8r"
   },
   "outputs": [],
   "source": [
    "#Carregamento de Bases de Dados Auxiliares\n",
    "#df_auxiliar_previous_application            = pd.read_csv(f\"{CSV_PATH}/previous_application.csv\")\n",
    "df_auxiliar_installments_payments           = pd.read_csv(f\"{CSV_PATH}/installments_payments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EaAcaQfAhN8s"
   },
   "outputs": [],
   "source": [
    "#Copia do df_train e df_test\n",
    "df_03_train = df_train.copy()\n",
    "df_03_test  = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fyfLHPp-hN8s"
   },
   "outputs": [],
   "source": [
    "#Realização do left join de df_train com df_auxiliar_previous_application\n",
    "# DF da esquerda = df_train\n",
    "# DF da direita  = df_auxiliar_previous_application\n",
    "df_03_train = df_03_train.join(df_auxiliar_previous_application, on='SK_ID_CURR', lsuffix = ' ', how='left')\n",
    "df_03_train = df_03_train.drop(columns={\"SK_ID_CURR\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_03_train com df_auxiliar_installments_payments\n",
    "# DF da esquerda = df_03_train\n",
    "# DF da direita  = df_auxiliar_installments_payments\n",
    "df_03_train = df_03_train.join(df_auxiliar_installments_payments, on='SK_ID_PREV', lsuffix = ' ',  how='left')\n",
    "df_03_train = df_03_train.drop(columns={\"SK_ID_PREV\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_test com df_auxiliar_previous_application\n",
    "# DF da esquerda = df_test\n",
    "# DF da direita  = df_auxiliar_previous_application\n",
    "df_03_test = df_03_test.join(df_auxiliar_previous_application, on='SK_ID_CURR', lsuffix = ' ', how='left')\n",
    "df_03_test = df_03_test.drop(columns={\"SK_ID_CURR\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_03_test com df_auxiliar_installments_payments\n",
    "# DF da esquerda = df_03_test\n",
    "# DF da direita  = df_auxiliar_installments_payments\n",
    "df_03_test = df_03_test.join(df_auxiliar_installments_payments, on='SK_ID_PREV', lsuffix = ' ',  how='left')\n",
    "df_03_test = df_03_test.drop(columns={\"SK_ID_PREV\"}) #Excluir coluna duplicada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lFPjyh9hN8s"
   },
   "source": [
    "## DataFrame 04 = application_train + previous_application + credit_card_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FChLLAPghN8s"
   },
   "outputs": [],
   "source": [
    "#Carregamento de Bases de Dados Auxiliares\n",
    "#df_auxiliar_previous_application            = pd.read_csv(f\"{CSV_PATH}/previous_application.csv\")\n",
    "df_auxiliar_credit_card_balances            = pd.read_csv(f\"{CSV_PATH}/credit_card_balance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cQTStY0ShN8t"
   },
   "outputs": [],
   "source": [
    "#Copia do df_train e df_test\n",
    "df_04_train = df_train.copy()\n",
    "df_04_test  = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PX556ef0hN8t"
   },
   "outputs": [],
   "source": [
    "#Realização do left join de df_train com df_auxiliar_previous_application\n",
    "# DF da esquerda = df_train\n",
    "# DF da direita  = df_auxiliar_previous_application\n",
    "df_04_train = df_04_train.join(df_auxiliar_previous_application, on='SK_ID_CURR', lsuffix = ' ', how='left')\n",
    "df_04_train = df_04_train.drop(columns={\"SK_ID_CURR\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_04_train com df_auxiliar_credit_card_balances\n",
    "# DF da esquerda = df_04_train\n",
    "# DF da direita  = df_auxiliar_credit_card_balances\n",
    "df_04_train = df_04_train.join(df_auxiliar_credit_card_balances, on='SK_ID_PREV', lsuffix = ' ',  how='left')\n",
    "df_04_train = df_04_train.drop(columns={\"SK_ID_PREV\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_test com df_auxiliar_previous_application\n",
    "# DF da esquerda = df_test\n",
    "# DF da direita  = df_auxiliar_previous_application\n",
    "df_04_test = df_04_test.join(df_auxiliar_previous_application, on='SK_ID_CURR', lsuffix = ' ', how='left')\n",
    "df_04_test = df_04_test.drop(columns={\"SK_ID_CURR\"}) #Excluir coluna duplicada\n",
    "\n",
    "#Realização do left join de df_04_test com df_auxiliar_credit_card_balances\n",
    "# DF da esquerda = df_04_test\n",
    "# DF da direita  = df_auxiliar_credit_card_balances\n",
    "df_04_test = df_04_test.join(df_auxiliar_credit_card_balances, on='SK_ID_PREV', lsuffix = ' ',  how='left')\n",
    "df_04_test = df_04_test.drop(columns={\"SK_ID_PREV\"}) #Excluir coluna duplicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EoQok1behN8t",
    "outputId": "2c02ba9a-550e-44b3-8750-5507ae3802b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 140) (307511, 165) (307511, 165) (307511, 180)\n",
      "(48744, 139) (48744, 164) (48744, 164) (48744, 179)\n"
     ]
    }
   ],
   "source": [
    "# Tamanhos dos Data Frames criados\n",
    "print(df_01_train.shape, df_02_train.shape, df_03_train.shape, df_04_train.shape)\n",
    "print(df_01_test.shape, df_02_test.shape, df_03_test.shape, df_04_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJjJF_XGhN8u"
   },
   "source": [
    "# PREPARAÇÃO DA BASE DE DADOS - Amostra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gI6kKG4ghN8v"
   },
   "source": [
    "Como as bases de dados original tem muitos valores, e as simulações subsequentes podem demorar muitas horas, realizar-se-a uma amostra aleatória das bases para treinamento e teste.\n",
    "Para deixar as bases com os mesmos SK_ID_CURR, faz-se primeiramente a amostragem via df_01, e para os demais dataframes selecionamos os valores dos atributos (colunas) do SK_ID_CURR do df_01. Isso faz com que o y_train seja único para os 4 df_x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "42r9hUZuhN8v"
   },
   "outputs": [],
   "source": [
    "#Amostra df_01_train\n",
    "df_01_amostrado = df_01_train.sample(frac=0.025, random_state=42)  # Seleciona 20% do DataFrame\n",
    "\n",
    "\n",
    "#Removendo colunas duplicadas\n",
    "lista_colunas_duplicadas_treino = [137]\n",
    "lista_colunas_duplicadas_teste  = [136]\n",
    "df_01_amostrado.drop(df_01_amostrado.columns[lista_colunas_duplicadas_treino], axis=1, inplace = True)\n",
    "df_01_test.drop(df_01_test.columns[lista_colunas_duplicadas_teste], axis=1, inplace = True)\n",
    "\n",
    "#Divisão treino\n",
    "X_train_df_01_amostrado =  df_01_amostrado.drop(columns={\"TARGET\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kbmaTkxFhN8v"
   },
   "outputs": [],
   "source": [
    "# y treino\n",
    "y_train =  df_01_amostrado.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3MT2_ItchN8v"
   },
   "outputs": [],
   "source": [
    "#Amostra df_02\n",
    "df_02_amostrado = df_02_train.loc[df_01_amostrado.index,:]\n",
    "\n",
    "\n",
    "#Removendo colunas duplicadas\n",
    "lista_colunas_duplicadas_treino = [158, 123, 124, 126, 128,  129, 130, 141, 162]\n",
    "lista_colunas_duplicadas_teste  = [157, 122, 123, 125, 127,  128, 129, 140, 161]\n",
    "df_02_amostrado.drop(df_02_amostrado.columns[lista_colunas_duplicadas_treino], axis=1, inplace = True)\n",
    "df_02_test.drop(df_02_test.columns[lista_colunas_duplicadas_teste], axis=1, inplace = True)\n",
    "\n",
    "# Limpar nomes das colunas (remover caracteres especiais inválidos para JSON)\n",
    "import re\n",
    "df_02_amostrado.columns = [re.sub(r'[^\\w]', '', col) for col in df_02_amostrado.columns]\n",
    "df_02_test.columns = [re.sub(r'[^\\w]', '', col) for col in df_02_test.columns]\n",
    "\n",
    "#Divisão treino\n",
    "X_train_df_02_amostrado =  df_02_amostrado.drop(columns={\"TARGET\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ddz5Wu0zhN8w"
   },
   "outputs": [],
   "source": [
    "#Amostra df_03\n",
    "df_03_amostrado = df_03_train.loc[df_01_amostrado.index,:]\n",
    "\n",
    "#Removendo colunas duplicadas\n",
    "lista_colunas_duplicadas_treino = [158, 123, 124, 126, 128, 129, 130, 141]\n",
    "lista_colunas_duplicadas_teste  = [157, 122, 123, 125, 127, 128, 129, 140]\n",
    "df_03_amostrado.drop(df_03_amostrado.columns[lista_colunas_duplicadas_treino], axis=1, inplace = True)\n",
    "df_03_test.drop(df_03_test.columns[lista_colunas_duplicadas_teste], axis=1, inplace = True)\n",
    "\n",
    "# Limpar nomes das colunas (remover caracteres especiais inválidos para JSON)\n",
    "import re\n",
    "df_03_amostrado.columns = [re.sub(r'[^\\w]', '', col) for col in df_03_amostrado.columns]\n",
    "df_03_test.columns = [re.sub(r'[^\\w]', '', col) for col in df_03_test.columns]\n",
    "\n",
    "#Divisão treino e teste\n",
    "X_train_df_03_amostrado =  df_03_amostrado.drop(columns={\"TARGET\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DCkZ7_KShN8w"
   },
   "outputs": [],
   "source": [
    "#Amostra df_04\n",
    "df_04_amostrado = df_04_train.loc[df_01_amostrado.index,:]\n",
    "\n",
    "\n",
    "#Removendo colunas duplicadas\n",
    "lista_colunas_duplicadas_treino = [158, 123, 124, 126, 128, 129, 130, 141, 177]\n",
    "lista_colunas_duplicadas_teste  = [157, 122, 123, 125, 127, 128, 129, 140, 176]\n",
    "df_04_amostrado.drop(df_04_amostrado.columns[lista_colunas_duplicadas_treino], axis=1, inplace = True)\n",
    "df_04_test.drop(df_04_test.columns[lista_colunas_duplicadas_teste], axis=1, inplace = True)\n",
    "\n",
    "# Limpar nomes das colunas (remover caracteres especiais inválidos para JSON)\n",
    "import re\n",
    "df_04_amostrado.columns = [re.sub(r'[^\\w]', '', col) for col in df_04_amostrado.columns]\n",
    "df_04_test.columns = [re.sub(r'[^\\w]', '', col) for col in df_04_test.columns]\n",
    "\n",
    "#Divisão treino e teste\n",
    "X_train_df_04_amostrado =  df_04_amostrado.drop(columns={\"TARGET\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ED50BII3hN8w"
   },
   "outputs": [],
   "source": [
    "#Excluindo dataframes da memória\n",
    "#del df_01, df_02, df_03, df_04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6uN3N9GhN8x"
   },
   "source": [
    "# 1. Treinamento Individual dos Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ToKRgzDvhN8x"
   },
   "outputs": [],
   "source": [
    "#Importanto as Bibliotecas dos classificadores\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_W70ssAQhN8x"
   },
   "outputs": [],
   "source": [
    "#Lista dos Modelos por Classificador\n",
    "modelos =   [('XGBOOST  - Config.01 - random_state=42, learning_rate = 0.3, max_depth = 6', XGBClassifier(random_state=42, learning_rate = 0.3, max_depth = 6)),\n",
    "             #('XGBOOST  - Config.02 - random_state=42, learning_rate = 0.3, max_depth = 8', XGBClassifier(random_state=42, learning_rate = 0.3, max_depth = 8)),\n",
    "             #('XGBOOST  - Config.03 - random_state=42, learning_rate = 0.2, max_depth = 6', XGBClassifier(random_state=42, learning_rate = 0.2, max_depth = 6)),\n",
    "             #('XGBOOST  - Config.04 - random_state=42, learning_rate = 0.2, max_depth = 8', XGBClassifier(random_state=42, learning_rate = 0.2, max_depth = 8)),\n",
    "             #('LIGHTGBM - Config.01 - random_state=42, learning_rate = 0.3, max_depth = 6', LGBMClassifier(random_state=42, learning_rate = 0.3, max_depth = 6, force_col_wise=True)),\n",
    "             #('LIGHTGBM - Config.02 - random_state=42, learning_rate = 0.3, max_depth = 8', LGBMClassifier(random_state=42, learning_rate = 0.3, max_depth = 8, force_col_wise=True)),\n",
    "             #('LIGHTGBM - Config.03 - random_state=42, learning_rate = 0.2, max_depth = 6', LGBMClassifier(random_state=42, learning_rate = 0.2, max_depth = 6, force_col_wise=True)),\n",
    "             #('LIGHTGBM - Config.04 - random_state=42, learning_rate = 0.2, max_depth = 8', LGBMClassifier(random_state=42, learning_rate = 0.2, max_depth = 8, force_col_wise=True)),\n",
    "             #('CATBOOST - Config.01 - random_state=42, learning_rate = 0.3, max_depth = 6', CatBoostClassifier(random_state=42, learning_rate = 0.3, max_depth = 6)),\n",
    "             #('CATBOOST - Config.02 - random_state=42, learning_rate = 0.3, max_depth = 8', CatBoostClassifier(random_state=42, learning_rate = 0.3, max_depth = 8)),\n",
    "             #('CATBOOST - Config.03 - random_state=42, learning_rate = 0.2, max_depth = 6', CatBoostClassifier(random_state=42, learning_rate = 0.2, max_depth = 6)),\n",
    "             #('CATBOOST - Config.04 - random_state=42, learning_rate = 0.2, max_depth = 8', CatBoostClassifier(random_state=42, learning_rate = 0.2, max_depth = 8)),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "T0WdRhyyhN8x"
   },
   "outputs": [],
   "source": [
    "#Transformando as variáveis catégóricas em binárias via get.dummies do df_01\n",
    "\n",
    "#Seleção dos atributos categóricos do df_01\n",
    "atributos_categoricos = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
    "                         'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
    "                         'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE',\n",
    "                         'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE',\n",
    "                         'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE',\n",
    "                         'CREDIT_ACTIVE', 'CREDIT_CURRENCY', 'CREDIT_TYPE', 'STATUS'\n",
    "]\n",
    "\n",
    "# Transformar usando pd.get_dummies\n",
    "X_train_df_01_amostrado_dummificado = pd.get_dummies(X_train_df_01_amostrado, columns=atributos_categoricos, drop_first=True)\n",
    "X_test_df_01_dummificado = pd.get_dummies(df_01_test, columns=atributos_categoricos, drop_first=True)\n",
    "\n",
    "# Limpar nomes das colunas (remover caracteres especiais inválidos para JSON)\n",
    "import re\n",
    "X_train_df_01_amostrado_dummificado.columns = [re.sub(r'[^\\w]', '', col) for col in X_train_df_01_amostrado_dummificado.columns]\n",
    "X_test_df_01_dummificado.columns = [re.sub(r'[^\\w]', '', col) for col in X_test_df_01_dummificado.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ewD_b1CZhN8x"
   },
   "outputs": [],
   "source": [
    "#Treino df_01\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "Resultados_df_01=[]\n",
    "for nome, classifier in modelos:\n",
    "  scores = cross_validate(classifier, X_train_df_01_amostrado_dummificado, y_train, scoring=['roc_auc'], cv = 10)\n",
    "  scores_roc_auc  = scores[\"test_roc_auc\"].mean()\n",
    "  Resultados_df_01.append({'Modelo': nome,\n",
    "                    'roc_auc': scores_roc_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WJOdH6_DhN88",
    "outputId": "5b25a798-6079-45a1-ceb2-19ce4ad8ae0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo \t\t\t\t\t\t\t\t\t\t\t ROC_UAC\n",
      "XGBOOST  - Config.01 - random_state=42, learning_rate = 0.3, max_depth = 6                0.6814\n"
     ]
    }
   ],
   "source": [
    "#Impressão dos Resultados df_01\n",
    "print(f'Modelo \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t ROC_UAC')\n",
    "for r in Resultados_df_01:\n",
    "    print(f'{r[\"Modelo\"]:<90}{r[\"roc_auc\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7gXMvEEthN89"
   },
   "outputs": [],
   "source": [
    "#Transformando as variáveis catégóricas em binárias via get.dummies do df_02\n",
    "\n",
    "#Seleção dos atributos categóricos do df_02\n",
    "atributos_categoricos = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
    "                         'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
    "                         'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE',\n",
    "                         'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE',\n",
    "                         'FLAG_LAST_APPL_PER_CONTRACT', 'NAME_CASH_LOAN_PURPOSE', 'NAME_CONTRACT_STATUS',\n",
    "                         'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON', 'NAME_CLIENT_TYPE', 'NAME_GOODS_CATEGORY',\n",
    "                         'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE', 'NAME_SELLER_INDUSTRY',\n",
    "                         'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION'\n",
    "                        ]\n",
    "\n",
    "# Transformar usando pd.get_dummies\n",
    "X_train_df_02_amostrado_dummificado = pd.get_dummies(X_train_df_02_amostrado, columns=atributos_categoricos, drop_first=True)\n",
    "X_test_df_02_dummificado = pd.get_dummies(df_02_test, columns=atributos_categoricos, drop_first=True)\n",
    "\n",
    "# Limpar nomes das colunas (remover caracteres especiais inválidos para JSON)\n",
    "import re\n",
    "X_train_df_02_amostrado_dummificado.columns = [re.sub(r'[^\\w]', '', col) for col in X_train_df_02_amostrado_dummificado.columns]\n",
    "X_test_df_02_dummificado.columns = [re.sub(r'[^\\w]', '', col) for col in X_test_df_02_dummificado.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lrZ4y0pchN9D"
   },
   "outputs": [],
   "source": [
    "#Treino df_02\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "Resultados_df_02=[]\n",
    "for nome, classifier in modelos:\n",
    "  scores = cross_validate(classifier, X_train_df_02_amostrado_dummificado, y_train, scoring=['roc_auc'], cv = 10)\n",
    "  scores_roc_auc  = scores[\"test_roc_auc\"].mean()\n",
    "  Resultados_df_02.append({'Modelo': nome,\n",
    "                    'roc_auc': scores_roc_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "VEYOHSeZhN9E",
    "outputId": "3f7b9d88-f9a3-47d8-f5cf-5e05bb7f1b77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo \t\t\t\t\t\t\t\t\t\t\t ROC_UAC\n",
      "XGBOOST  - Config.01 - random_state=42, learning_rate = 0.3, max_depth = 6                0.6831\n"
     ]
    }
   ],
   "source": [
    "#Impressão dos Resultados df_02\n",
    "print(f'Modelo \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t ROC_UAC')\n",
    "for r in Resultados_df_02:\n",
    "    print(f'{r[\"Modelo\"]:<90}{r[\"roc_auc\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "2nISFeMhhN9E"
   },
   "outputs": [],
   "source": [
    "#Transformando as variáveis categóricas em binárias via get.dummies do df_03\n",
    "\n",
    "#Seleção dos atributos categóricos do df_03\n",
    "atributos_categoricos = [\"NAME_CONTRACT_TYPE\", \"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\", \"NAME_TYPE_SUITE\",\n",
    "                        \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"NAME_FAMILY_STATUS\", \"NAME_HOUSING_TYPE\",\n",
    "                        \"OCCUPATION_TYPE\", \"WEEKDAY_APPR_PROCESS_START\", \"ORGANIZATION_TYPE\", \"FONDKAPREMONT_MODE\",\n",
    "                        \"HOUSETYPE_MODE\", \"WALLSMATERIAL_MODE\", \"EMERGENCYSTATE_MODE\", \"FLAG_LAST_APPL_PER_CONTRACT\",\n",
    "                        \"NAME_CASH_LOAN_PURPOSE\", \"NAME_CONTRACT_STATUS\", \"NAME_PAYMENT_TYPE\", \"CODE_REJECT_REASON\",\n",
    "                        \"NAME_CLIENT_TYPE\", \"NAME_GOODS_CATEGORY\", \"NAME_PORTFOLIO\", \"NAME_PRODUCT_TYPE\", \"CHANNEL_TYPE\",\n",
    "                        \"NAME_SELLER_INDUSTRY\",\"NAME_YIELD_GROUP\", \"PRODUCT_COMBINATION\"]\n",
    "\n",
    "# Transformar usando pd.get_dummies\n",
    "X_train_df_03_amostrado_dummificado = pd.get_dummies(X_train_df_03_amostrado, columns=atributos_categoricos, drop_first=True)\n",
    "X_test_df_03_dummificado = pd.get_dummies(df_03_test, columns=atributos_categoricos, drop_first=True)\n",
    "\n",
    "# Limpar nomes das colunas (remover caracteres especiais inválidos para JSON)\n",
    "import re\n",
    "X_train_df_03_amostrado_dummificado.columns = [re.sub(r'[^\\w]', '', col) for col in X_train_df_03_amostrado_dummificado.columns]\n",
    "X_test_df_03_dummificado.columns = [re.sub(r'[^\\w]', '', col) for col in X_test_df_03_dummificado.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "z8nMNCe4hN9F"
   },
   "outputs": [],
   "source": [
    "#Treino df_03\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "Resultados_df_03=[]\n",
    "for nome, classifier in modelos:\n",
    "  scores = cross_validate(classifier, X_train_df_03_amostrado_dummificado, y_train, scoring=['roc_auc'], cv = 10)\n",
    "  scores_roc_auc  = scores[\"test_roc_auc\"].mean()\n",
    "  Resultados_df_03.append({'Modelo': nome,\n",
    "                    'roc_auc': scores_roc_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "w9A8rUkmhN9F",
    "outputId": "334bfccc-18dc-4b52-a4b5-cc616a5d0200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo \t\t\t\t\t\t\t\t\t\t\t ROC_UAC\n",
      "XGBOOST  - Config.01 - random_state=42, learning_rate = 0.3, max_depth = 6                0.6885\n"
     ]
    }
   ],
   "source": [
    "#Impressão dos Resultados df_03\n",
    "print(f'Modelo \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t ROC_UAC')\n",
    "for r in Resultados_df_03:\n",
    "    print(f'{r[\"Modelo\"]:<90}{r[\"roc_auc\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "eFaq7E0XhN9F"
   },
   "outputs": [],
   "source": [
    "#Transformando as variáveis categóricas em binárias via get.dummies do df_04\n",
    "\n",
    "#Seleção dos atributos categóricos do df_04\n",
    "atributos_categoricos = [\"NAME_CONTRACT_TYPE\", \"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\",\n",
    "                         \"NAME_TYPE_SUITE\", \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\",\n",
    "                         \"NAME_FAMILY_STATUS\", \"NAME_HOUSING_TYPE\", \"OCCUPATION_TYPE\",\n",
    "                         \"WEEKDAY_APPR_PROCESS_START\", \"ORGANIZATION_TYPE\", \"FONDKAPREMONT_MODE\",\n",
    "                         \"HOUSETYPE_MODE\", \"WALLSMATERIAL_MODE\", \"EMERGENCYSTATE_MODE\",\n",
    "                         \"FLAG_LAST_APPL_PER_CONTRACT\", \"NAME_CASH_LOAN_PURPOSE\",\n",
    "                         \"NAME_CONTRACT_STATUS\", \"NAME_PAYMENT_TYPE\", \"CODE_REJECT_REASON\",\n",
    "                         \"NAME_CLIENT_TYPE\", \"NAME_GOODS_CATEGORY\", \"NAME_PORTFOLIO\",\n",
    "                         \"NAME_PRODUCT_TYPE\", \"CHANNEL_TYPE\", \"NAME_SELLER_INDUSTRY\",\n",
    "                         \"NAME_YIELD_GROUP\", \"PRODUCT_COMBINATION\"\n",
    "                        ]\n",
    "\n",
    "# Transformar usando pd.get_dummies\n",
    "X_train_df_04_amostrado_dummificado = pd.get_dummies(X_train_df_04_amostrado, columns=atributos_categoricos, drop_first=True)\n",
    "X_test_df_04_dummificado = pd.get_dummies(df_04_test, columns=atributos_categoricos, drop_first=True)\n",
    "\n",
    "# Limpar nomes das colunas (remover caracteres especiais inválidos para JSON)\n",
    "import re\n",
    "X_train_df_04_amostrado_dummificado.columns = [re.sub(r'[^\\w]', '', col) for col in X_train_df_04_amostrado_dummificado.columns]\n",
    "X_test_df_04_dummificado.columns = [re.sub(r'[^\\w]', '', col) for col in X_test_df_04_dummificado.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "R-JSTZXThN9G"
   },
   "outputs": [],
   "source": [
    "#Treino df_04\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "Resultados_df_04=[]\n",
    "for nome, classifier in modelos:\n",
    "  scores = cross_validate(classifier, X_train_df_04_amostrado_dummificado, y_train, scoring=['roc_auc'], cv = 10)\n",
    "  scores_roc_auc  = scores[\"test_roc_auc\"].mean()\n",
    "  Resultados_df_04.append({'Modelo': nome,\n",
    "                    'roc_auc': scores_roc_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "0iPrHElahN9G",
    "outputId": "04d470e3-eea4-49e0-cda7-56eb8aaee8d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo \t\t\t\t\t\t\t\t\t\t\t ROC_UAC\n",
      "XGBOOST  - Config.01 - random_state=42, learning_rate = 0.3, max_depth = 6                0.6828\n"
     ]
    }
   ],
   "source": [
    "#Impressão dos Resultados df_04\n",
    "print(f'Modelo \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t ROC_UAC')\n",
    "for r in Resultados_df_04:\n",
    "    print(f'{r[\"Modelo\"]:<90}{r[\"roc_auc\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTwB2Ho2hN9H"
   },
   "source": [
    "# 2. Combinação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njVl8rfAhN9H"
   },
   "source": [
    "Pegou-se os modelos com melhores resultados dos dataframes df_01, df_02, df_03 e df_04 e aplicou a estratégia de combinação deles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "mVKbgZvXhN9H"
   },
   "outputs": [],
   "source": [
    "#Importando Bibliotecas pertinentes\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "nN5PInochN9H"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "hQXzfHZxhN9I"
   },
   "outputs": [],
   "source": [
    "# def avaliar_modelo(modelo, X, y, nome=\"Modelo\"):\n",
    "#     roc_auc = []\n",
    "#     for train_idx, test_idx in skf.split(X, y):\n",
    "#         X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "#         modelo.fit(X_train, y_train)\n",
    "#         preds = modelo.predict(X_test)\n",
    "#         roc_auc.append(roc_auc_score(y_test, preds))\n",
    "#     print(f\"{nome}: roc_auc = {np.mean(roc_auc):.4f}, desvio padrão = {np.std(roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "d5Hci1VFhN9I"
   },
   "outputs": [],
   "source": [
    "#Função para avaliar modelo combinado\n",
    "def avaliar_modelo(modelo, X1, X2, X3, X4, y, nome=\"ModeloModeloCombinado - Voto da Maioria\"): # Modelo único\n",
    "    roc_auc = [] #Criação da lista roc_auc\n",
    "    for train_idx, test_idx in skf.split(X1, y): # O método .split(X1, y) divide os dados em índices de treino e teste para cada fold (partição) da validação cruzada.\n",
    "                                                 # train_idx e test_idx são arrays de índices que indicam quais amostras vão para o conjunto de treino e teste, respectivamente.\n",
    "        #Dividindo quatro DataFrames de entrada (X1, X2, X3, X4) em conjuntos de treino e teste, usando os mesmos índices.\n",
    "        X1_train, X1_test = X1.iloc[train_idx], X1.iloc[test_idx]\n",
    "        X2_train, X2_test = X2.iloc[train_idx], X2.iloc[test_idx]\n",
    "        X3_train, X3_test = X3.iloc[train_idx], X3.iloc[test_idx]\n",
    "        X4_train, X4_test = X4.iloc[train_idx], X4.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        #Realizando o treinamento com base no X1_train\n",
    "        modelo.fit(X1_train, y_train)\n",
    "        #Realizando a predição com base no X1_teste\n",
    "        preds_1 = modelo.predict(X1_test)\n",
    "\n",
    "        #Realizando o treinamento com base no X2_train\n",
    "        modelo.fit(X2_train, y_train)\n",
    "        #Realizando a predição com base no X2_teste\n",
    "        preds_2 = modelo.predict(X2_test)\n",
    "\n",
    "        #Realizando o treinamento com base no X3_train\n",
    "        modelo.fit(X3_train, y_train)\n",
    "        #Realizando a predição com base no X3_teste\n",
    "        preds_3 = modelo.predict(X3_test)\n",
    "\n",
    "        #Realizando o treinamento com base no X4_train\n",
    "        modelo.fit(X4_train, y_train)\n",
    "        #Realizando a predição com base no X4_teste\n",
    "        preds_4 = modelo.predict(X4_test)\n",
    "\n",
    "        #Realizando a soma das 4 predições\n",
    "        soma = preds_1 + preds_2 + preds_3 + preds_4\n",
    "\n",
    "        #Saida Final da prediçã. Voto da maioria\n",
    "        preds = [1 if s > 2 else 0 for s in soma]\n",
    "\n",
    "        ##Calculo da mémétrica roc_auc\n",
    "        roc_auc.append(roc_auc_score(y_test, preds))\n",
    "\n",
    "    print(f\"{nome}: roc_auc = {np.mean(roc_auc):.4f}, desvio padrão = {np.std(roc_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "MuUgMXSzhN9I",
    "outputId": "e0e25025-3c4a-49f0-eb76-85e885c976c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeloCombinado: roc_auc = 0.5045, desvio padrão = 0.0074\n"
     ]
    }
   ],
   "source": [
    "#Definindo o modelo que será utilizado\n",
    "estimador_df = XGBClassifier(random_state=42, learning_rate = 0.3, max_depth = 6)\n",
    "\n",
    "#Definição de quem será os X's_train e y_train\n",
    "X1 = X_train_df_01_amostrado_dummificado.copy()\n",
    "X2 = X_train_df_02_amostrado_dummificado.copy()\n",
    "X3 = X_train_df_03_amostrado_dummificado.copy()\n",
    "X4 = X_train_df_04_amostrado_dummificado.copy()\n",
    "y = y_train\n",
    "\n",
    "X1_test = X_test_df_01_dummificado.copy()\n",
    "X2_test = X_test_df_02_dummificado.copy()\n",
    "X3_test = X_test_df_03_dummificado.copy()\n",
    "X4_test = X_test_df_04_dummificado.copy()\n",
    "\n",
    "#Invocação da função avaliar modelo\n",
    "# A função tem como parâmetros de entra o estimador_df (modelo), os X's dos respectivos dataframes, o y (TARGET) e o nome do modelo\n",
    "avaliar_modelo(estimador_df, X1, X2, X3, X4, y, \"ModeloCombinado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['SK_ID_CURR', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'SK_ID_BUREAU', 'DAYS_CREDIT', 'CREDIT_DAY_OVERDUE', 'DAYS_CREDIT_ENDDATE', 'DAYS_ENDDATE_FACT', 'AMT_CREDIT_MAX_OVERDUE', 'CNT_CREDIT_PROLONG', 'AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM_LIMIT', 'AMT_CREDIT_SUM_OVERDUE', 'DAYS_CREDIT_UPDATE', 'MONTHS_BALANCE', 'NAME_CONTRACT_TYPE_Revolvingloans', 'CODE_GENDER_M', 'FLAG_OWN_CAR_Y', 'FLAG_OWN_REALTY_Y', 'NAME_TYPE_SUITE_Family', 'NAME_TYPE_SUITE_Groupofpeople', 'NAME_TYPE_SUITE_Other_A', 'NAME_TYPE_SUITE_Other_B', 'NAME_TYPE_SUITE_Spousepartner', 'NAME_TYPE_SUITE_Unaccompanied', 'NAME_INCOME_TYPE_Maternityleave', 'NAME_INCOME_TYPE_Pensioner', 'NAME_INCOME_TYPE_Stateservant', 'NAME_INCOME_TYPE_Student', 'NAME_INCOME_TYPE_Working', 'NAME_EDUCATION_TYPE_Highereducation', 'NAME_EDUCATION_TYPE_Incompletehigher', 'NAME_EDUCATION_TYPE_Lowersecondary', 'NAME_EDUCATION_TYPE_Secondarysecondaryspecial', 'NAME_FAMILY_STATUS_Married', 'NAME_FAMILY_STATUS_Separated', 'NAME_FAMILY_STATUS_Singlenotmarried', 'NAME_FAMILY_STATUS_Unknown', 'NAME_FAMILY_STATUS_Widow', 'NAME_HOUSING_TYPE_Houseapartment', 'NAME_HOUSING_TYPE_Municipalapartment', 'NAME_HOUSING_TYPE_Officeapartment', 'NAME_HOUSING_TYPE_Rentedapartment', 'NAME_HOUSING_TYPE_Withparents', 'OCCUPATION_TYPE_Cleaningstaff', 'OCCUPATION_TYPE_Cookingstaff', 'OCCUPATION_TYPE_Corestaff', 'OCCUPATION_TYPE_Drivers', 'OCCUPATION_TYPE_HRstaff', 'OCCUPATION_TYPE_Highskilltechstaff', 'OCCUPATION_TYPE_ITstaff', 'OCCUPATION_TYPE_Laborers', 'OCCUPATION_TYPE_LowskillLaborers', 'OCCUPATION_TYPE_Managers', 'OCCUPATION_TYPE_Medicinestaff', 'OCCUPATION_TYPE_Privateservicestaff', 'OCCUPATION_TYPE_Realtyagents', 'OCCUPATION_TYPE_Salesstaff', 'OCCUPATION_TYPE_Secretaries', 'OCCUPATION_TYPE_Securitystaff', 'OCCUPATION_TYPE_Waitersbarmenstaff', 'WEEKDAY_APPR_PROCESS_START_MONDAY', 'WEEKDAY_APPR_PROCESS_START_SATURDAY', 'WEEKDAY_APPR_PROCESS_START_SUNDAY', 'WEEKDAY_APPR_PROCESS_START_THURSDAY', 'WEEKDAY_APPR_PROCESS_START_TUESDAY', 'WEEKDAY_APPR_PROCESS_START_WEDNESDAY', 'ORGANIZATION_TYPE_Agriculture', 'ORGANIZATION_TYPE_Bank', 'ORGANIZATION_TYPE_BusinessEntityType1', 'ORGANIZATION_TYPE_BusinessEntityType2', 'ORGANIZATION_TYPE_BusinessEntityType3', 'ORGANIZATION_TYPE_Cleaning', 'ORGANIZATION_TYPE_Construction', 'ORGANIZATION_TYPE_Culture', 'ORGANIZATION_TYPE_Electricity', 'ORGANIZATION_TYPE_Emergency', 'ORGANIZATION_TYPE_Government', 'ORGANIZATION_TYPE_Hotel', 'ORGANIZATION_TYPE_Housing', 'ORGANIZATION_TYPE_Industrytype1', 'ORGANIZATION_TYPE_Industrytype10', 'ORGANIZATION_TYPE_Industrytype11', 'ORGANIZATION_TYPE_Industrytype12', 'ORGANIZATION_TYPE_Industrytype13', 'ORGANIZATION_TYPE_Industrytype2', 'ORGANIZATION_TYPE_Industrytype3', 'ORGANIZATION_TYPE_Industrytype4', 'ORGANIZATION_TYPE_Industrytype5', 'ORGANIZATION_TYPE_Industrytype6', 'ORGANIZATION_TYPE_Industrytype7', 'ORGANIZATION_TYPE_Industrytype9', 'ORGANIZATION_TYPE_Insurance', 'ORGANIZATION_TYPE_Kindergarten', 'ORGANIZATION_TYPE_LegalServices', 'ORGANIZATION_TYPE_Medicine', 'ORGANIZATION_TYPE_Military', 'ORGANIZATION_TYPE_Mobile', 'ORGANIZATION_TYPE_Other', 'ORGANIZATION_TYPE_Police', 'ORGANIZATION_TYPE_Postal', 'ORGANIZATION_TYPE_Realtor', 'ORGANIZATION_TYPE_Religion', 'ORGANIZATION_TYPE_Restaurant', 'ORGANIZATION_TYPE_School', 'ORGANIZATION_TYPE_Security', 'ORGANIZATION_TYPE_SecurityMinistries', 'ORGANIZATION_TYPE_Selfemployed', 'ORGANIZATION_TYPE_Services', 'ORGANIZATION_TYPE_Telecom', 'ORGANIZATION_TYPE_Tradetype1', 'ORGANIZATION_TYPE_Tradetype2', 'ORGANIZATION_TYPE_Tradetype3', 'ORGANIZATION_TYPE_Tradetype4', 'ORGANIZATION_TYPE_Tradetype5', 'ORGANIZATION_TYPE_Tradetype6', 'ORGANIZATION_TYPE_Tradetype7', 'ORGANIZATION_TYPE_Transporttype1', 'ORGANIZATION_TYPE_Transporttype2', 'ORGANIZATION_TYPE_Transporttype3', 'ORGANIZATION_TYPE_Transporttype4', 'ORGANIZATION_TYPE_University', 'ORGANIZATION_TYPE_XNA', 'FONDKAPREMONT_MODE_orgspecaccount', 'FONDKAPREMONT_MODE_regoperaccount', 'FONDKAPREMONT_MODE_regoperspecaccount', 'HOUSETYPE_MODE_specifichousing', 'HOUSETYPE_MODE_terracedhouse', 'WALLSMATERIAL_MODE_Mixed', 'WALLSMATERIAL_MODE_Monolithic', 'WALLSMATERIAL_MODE_Others', 'WALLSMATERIAL_MODE_Panel', 'WALLSMATERIAL_MODE_Stonebrick', 'WALLSMATERIAL_MODE_Wooden', 'EMERGENCYSTATE_MODE_Yes', 'CREDIT_ACTIVE_Closed', 'CREDIT_ACTIVE_Sold', 'CREDIT_CURRENCY_currency2', 'CREDIT_TYPE_Carloan', 'CREDIT_TYPE_Consumercredit', 'CREDIT_TYPE_Creditcard', 'CREDIT_TYPE_Loanforbusinessdevelopment', 'CREDIT_TYPE_Loanforthepurchaseofequipment', 'CREDIT_TYPE_Loanforworkingcapitalreplenishment', 'CREDIT_TYPE_Microloan', 'CREDIT_TYPE_Mortgage', 'CREDIT_TYPE_Unknowntypeofloan', 'STATUS_1', 'STATUS_2', 'STATUS_3', 'STATUS_4', 'STATUS_5', 'STATUS_C', 'STATUS_X'] ['SK_ID_CURR', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'SK_ID_BUREAU', 'DAYS_CREDIT', 'CREDIT_DAY_OVERDUE', 'DAYS_CREDIT_ENDDATE', 'DAYS_ENDDATE_FACT', 'AMT_CREDIT_MAX_OVERDUE', 'CNT_CREDIT_PROLONG', 'AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM_LIMIT', 'AMT_CREDIT_SUM_OVERDUE', 'DAYS_CREDIT_UPDATE', 'MONTHS_BALANCE', 'NAME_CONTRACT_TYPE_Revolvingloans', 'CODE_GENDER_M', 'FLAG_OWN_CAR_Y', 'FLAG_OWN_REALTY_Y', 'NAME_TYPE_SUITE_Family', 'NAME_TYPE_SUITE_Groupofpeople', 'NAME_TYPE_SUITE_Other_A', 'NAME_TYPE_SUITE_Other_B', 'NAME_TYPE_SUITE_Spousepartner', 'NAME_TYPE_SUITE_Unaccompanied', 'NAME_INCOME_TYPE_Commercialassociate', 'NAME_INCOME_TYPE_Pensioner', 'NAME_INCOME_TYPE_Stateservant', 'NAME_INCOME_TYPE_Student', 'NAME_INCOME_TYPE_Unemployed', 'NAME_INCOME_TYPE_Working', 'NAME_EDUCATION_TYPE_Highereducation', 'NAME_EDUCATION_TYPE_Incompletehigher', 'NAME_EDUCATION_TYPE_Lowersecondary', 'NAME_EDUCATION_TYPE_Secondarysecondaryspecial', 'NAME_FAMILY_STATUS_Married', 'NAME_FAMILY_STATUS_Separated', 'NAME_FAMILY_STATUS_Singlenotmarried', 'NAME_FAMILY_STATUS_Widow', 'NAME_HOUSING_TYPE_Houseapartment', 'NAME_HOUSING_TYPE_Municipalapartment', 'NAME_HOUSING_TYPE_Officeapartment', 'NAME_HOUSING_TYPE_Rentedapartment', 'NAME_HOUSING_TYPE_Withparents', 'OCCUPATION_TYPE_Cleaningstaff', 'OCCUPATION_TYPE_Cookingstaff', 'OCCUPATION_TYPE_Corestaff', 'OCCUPATION_TYPE_Drivers', 'OCCUPATION_TYPE_HRstaff', 'OCCUPATION_TYPE_Highskilltechstaff', 'OCCUPATION_TYPE_ITstaff', 'OCCUPATION_TYPE_Laborers', 'OCCUPATION_TYPE_LowskillLaborers', 'OCCUPATION_TYPE_Managers', 'OCCUPATION_TYPE_Medicinestaff', 'OCCUPATION_TYPE_Privateservicestaff', 'OCCUPATION_TYPE_Realtyagents', 'OCCUPATION_TYPE_Salesstaff', 'OCCUPATION_TYPE_Secretaries', 'OCCUPATION_TYPE_Securitystaff', 'OCCUPATION_TYPE_Waitersbarmenstaff', 'WEEKDAY_APPR_PROCESS_START_MONDAY', 'WEEKDAY_APPR_PROCESS_START_SATURDAY', 'WEEKDAY_APPR_PROCESS_START_SUNDAY', 'WEEKDAY_APPR_PROCESS_START_THURSDAY', 'WEEKDAY_APPR_PROCESS_START_TUESDAY', 'WEEKDAY_APPR_PROCESS_START_WEDNESDAY', 'ORGANIZATION_TYPE_Agriculture', 'ORGANIZATION_TYPE_Bank', 'ORGANIZATION_TYPE_BusinessEntityType1', 'ORGANIZATION_TYPE_BusinessEntityType2', 'ORGANIZATION_TYPE_BusinessEntityType3', 'ORGANIZATION_TYPE_Cleaning', 'ORGANIZATION_TYPE_Construction', 'ORGANIZATION_TYPE_Culture', 'ORGANIZATION_TYPE_Electricity', 'ORGANIZATION_TYPE_Emergency', 'ORGANIZATION_TYPE_Government', 'ORGANIZATION_TYPE_Hotel', 'ORGANIZATION_TYPE_Housing', 'ORGANIZATION_TYPE_Industrytype1', 'ORGANIZATION_TYPE_Industrytype10', 'ORGANIZATION_TYPE_Industrytype11', 'ORGANIZATION_TYPE_Industrytype12', 'ORGANIZATION_TYPE_Industrytype13', 'ORGANIZATION_TYPE_Industrytype2', 'ORGANIZATION_TYPE_Industrytype3', 'ORGANIZATION_TYPE_Industrytype4', 'ORGANIZATION_TYPE_Industrytype5', 'ORGANIZATION_TYPE_Industrytype6', 'ORGANIZATION_TYPE_Industrytype7', 'ORGANIZATION_TYPE_Industrytype8', 'ORGANIZATION_TYPE_Industrytype9', 'ORGANIZATION_TYPE_Insurance', 'ORGANIZATION_TYPE_Kindergarten', 'ORGANIZATION_TYPE_LegalServices', 'ORGANIZATION_TYPE_Medicine', 'ORGANIZATION_TYPE_Military', 'ORGANIZATION_TYPE_Mobile', 'ORGANIZATION_TYPE_Other', 'ORGANIZATION_TYPE_Police', 'ORGANIZATION_TYPE_Postal', 'ORGANIZATION_TYPE_Realtor', 'ORGANIZATION_TYPE_Religion', 'ORGANIZATION_TYPE_Restaurant', 'ORGANIZATION_TYPE_School', 'ORGANIZATION_TYPE_Security', 'ORGANIZATION_TYPE_SecurityMinistries', 'ORGANIZATION_TYPE_Selfemployed', 'ORGANIZATION_TYPE_Services', 'ORGANIZATION_TYPE_Telecom', 'ORGANIZATION_TYPE_Tradetype1', 'ORGANIZATION_TYPE_Tradetype2', 'ORGANIZATION_TYPE_Tradetype3', 'ORGANIZATION_TYPE_Tradetype4', 'ORGANIZATION_TYPE_Tradetype5', 'ORGANIZATION_TYPE_Tradetype6', 'ORGANIZATION_TYPE_Tradetype7', 'ORGANIZATION_TYPE_Transporttype1', 'ORGANIZATION_TYPE_Transporttype2', 'ORGANIZATION_TYPE_Transporttype3', 'ORGANIZATION_TYPE_Transporttype4', 'ORGANIZATION_TYPE_University', 'ORGANIZATION_TYPE_XNA', 'FONDKAPREMONT_MODE_orgspecaccount', 'FONDKAPREMONT_MODE_regoperaccount', 'FONDKAPREMONT_MODE_regoperspecaccount', 'HOUSETYPE_MODE_specifichousing', 'HOUSETYPE_MODE_terracedhouse', 'WALLSMATERIAL_MODE_Mixed', 'WALLSMATERIAL_MODE_Monolithic', 'WALLSMATERIAL_MODE_Others', 'WALLSMATERIAL_MODE_Panel', 'WALLSMATERIAL_MODE_Stonebrick', 'WALLSMATERIAL_MODE_Wooden', 'EMERGENCYSTATE_MODE_Yes', 'CREDIT_ACTIVE_Closed', 'CREDIT_ACTIVE_Sold', 'CREDIT_CURRENCY_currency2', 'CREDIT_CURRENCY_currency3', 'CREDIT_TYPE_Carloan', 'CREDIT_TYPE_Cashloannonearmarked', 'CREDIT_TYPE_Consumercredit', 'CREDIT_TYPE_Creditcard', 'CREDIT_TYPE_Loanforbusinessdevelopment', 'CREDIT_TYPE_Loanforworkingcapitalreplenishment', 'CREDIT_TYPE_Microloan', 'CREDIT_TYPE_Mortgage', 'CREDIT_TYPE_Unknowntypeofloan', 'STATUS_1', 'STATUS_2', 'STATUS_3', 'STATUS_4', 'STATUS_5', 'STATUS_C', 'STATUS_X']\nexpected CREDIT_TYPE_Loanforthepurchaseofequipment, NAME_FAMILY_STATUS_Unknown, NAME_INCOME_TYPE_Maternityleave in input data\ntraining data did not have the following fields: CREDIT_TYPE_Cashloannonearmarked, NAME_INCOME_TYPE_Unemployed, NAME_INCOME_TYPE_Commercialassociate, CREDIT_CURRENCY_currency3, ORGANIZATION_TYPE_Industrytype8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m estimador_df\u001b[38;5;241m.\u001b[39mfit(X1, y)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Realizando a predição com base no X1_teste\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m preds_1 \u001b[38;5;241m=\u001b[39m \u001b[43mestimador_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Realizando o treinamento com base no X2\u001b[39;00m\n\u001b[0;32m      9\u001b[0m estimador_df\u001b[38;5;241m.\u001b[39mfit(X2, y)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1718\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[0;32m   1708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1709\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1715\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1716\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1718\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1719\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1725\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1726\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1727\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1327\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1327\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1335\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1336\u001b[0m             cp \u001b[38;5;241m=\u001b[39m import_cupy()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\xgboost\\core.py:2667\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2665\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2667\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2669\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\xgboost\\core.py:3243\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   3237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   3238\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3240\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   3241\u001b[0m     )\n\u001b[1;32m-> 3243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['SK_ID_CURR', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'SK_ID_BUREAU', 'DAYS_CREDIT', 'CREDIT_DAY_OVERDUE', 'DAYS_CREDIT_ENDDATE', 'DAYS_ENDDATE_FACT', 'AMT_CREDIT_MAX_OVERDUE', 'CNT_CREDIT_PROLONG', 'AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM_LIMIT', 'AMT_CREDIT_SUM_OVERDUE', 'DAYS_CREDIT_UPDATE', 'MONTHS_BALANCE', 'NAME_CONTRACT_TYPE_Revolvingloans', 'CODE_GENDER_M', 'FLAG_OWN_CAR_Y', 'FLAG_OWN_REALTY_Y', 'NAME_TYPE_SUITE_Family', 'NAME_TYPE_SUITE_Groupofpeople', 'NAME_TYPE_SUITE_Other_A', 'NAME_TYPE_SUITE_Other_B', 'NAME_TYPE_SUITE_Spousepartner', 'NAME_TYPE_SUITE_Unaccompanied', 'NAME_INCOME_TYPE_Maternityleave', 'NAME_INCOME_TYPE_Pensioner', 'NAME_INCOME_TYPE_Stateservant', 'NAME_INCOME_TYPE_Student', 'NAME_INCOME_TYPE_Working', 'NAME_EDUCATION_TYPE_Highereducation', 'NAME_EDUCATION_TYPE_Incompletehigher', 'NAME_EDUCATION_TYPE_Lowersecondary', 'NAME_EDUCATION_TYPE_Secondarysecondaryspecial', 'NAME_FAMILY_STATUS_Married', 'NAME_FAMILY_STATUS_Separated', 'NAME_FAMILY_STATUS_Singlenotmarried', 'NAME_FAMILY_STATUS_Unknown', 'NAME_FAMILY_STATUS_Widow', 'NAME_HOUSING_TYPE_Houseapartment', 'NAME_HOUSING_TYPE_Municipalapartment', 'NAME_HOUSING_TYPE_Officeapartment', 'NAME_HOUSING_TYPE_Rentedapartment', 'NAME_HOUSING_TYPE_Withparents', 'OCCUPATION_TYPE_Cleaningstaff', 'OCCUPATION_TYPE_Cookingstaff', 'OCCUPATION_TYPE_Corestaff', 'OCCUPATION_TYPE_Drivers', 'OCCUPATION_TYPE_HRstaff', 'OCCUPATION_TYPE_Highskilltechstaff', 'OCCUPATION_TYPE_ITstaff', 'OCCUPATION_TYPE_Laborers', 'OCCUPATION_TYPE_LowskillLaborers', 'OCCUPATION_TYPE_Managers', 'OCCUPATION_TYPE_Medicinestaff', 'OCCUPATION_TYPE_Privateservicestaff', 'OCCUPATION_TYPE_Realtyagents', 'OCCUPATION_TYPE_Salesstaff', 'OCCUPATION_TYPE_Secretaries', 'OCCUPATION_TYPE_Securitystaff', 'OCCUPATION_TYPE_Waitersbarmenstaff', 'WEEKDAY_APPR_PROCESS_START_MONDAY', 'WEEKDAY_APPR_PROCESS_START_SATURDAY', 'WEEKDAY_APPR_PROCESS_START_SUNDAY', 'WEEKDAY_APPR_PROCESS_START_THURSDAY', 'WEEKDAY_APPR_PROCESS_START_TUESDAY', 'WEEKDAY_APPR_PROCESS_START_WEDNESDAY', 'ORGANIZATION_TYPE_Agriculture', 'ORGANIZATION_TYPE_Bank', 'ORGANIZATION_TYPE_BusinessEntityType1', 'ORGANIZATION_TYPE_BusinessEntityType2', 'ORGANIZATION_TYPE_BusinessEntityType3', 'ORGANIZATION_TYPE_Cleaning', 'ORGANIZATION_TYPE_Construction', 'ORGANIZATION_TYPE_Culture', 'ORGANIZATION_TYPE_Electricity', 'ORGANIZATION_TYPE_Emergency', 'ORGANIZATION_TYPE_Government', 'ORGANIZATION_TYPE_Hotel', 'ORGANIZATION_TYPE_Housing', 'ORGANIZATION_TYPE_Industrytype1', 'ORGANIZATION_TYPE_Industrytype10', 'ORGANIZATION_TYPE_Industrytype11', 'ORGANIZATION_TYPE_Industrytype12', 'ORGANIZATION_TYPE_Industrytype13', 'ORGANIZATION_TYPE_Industrytype2', 'ORGANIZATION_TYPE_Industrytype3', 'ORGANIZATION_TYPE_Industrytype4', 'ORGANIZATION_TYPE_Industrytype5', 'ORGANIZATION_TYPE_Industrytype6', 'ORGANIZATION_TYPE_Industrytype7', 'ORGANIZATION_TYPE_Industrytype9', 'ORGANIZATION_TYPE_Insurance', 'ORGANIZATION_TYPE_Kindergarten', 'ORGANIZATION_TYPE_LegalServices', 'ORGANIZATION_TYPE_Medicine', 'ORGANIZATION_TYPE_Military', 'ORGANIZATION_TYPE_Mobile', 'ORGANIZATION_TYPE_Other', 'ORGANIZATION_TYPE_Police', 'ORGANIZATION_TYPE_Postal', 'ORGANIZATION_TYPE_Realtor', 'ORGANIZATION_TYPE_Religion', 'ORGANIZATION_TYPE_Restaurant', 'ORGANIZATION_TYPE_School', 'ORGANIZATION_TYPE_Security', 'ORGANIZATION_TYPE_SecurityMinistries', 'ORGANIZATION_TYPE_Selfemployed', 'ORGANIZATION_TYPE_Services', 'ORGANIZATION_TYPE_Telecom', 'ORGANIZATION_TYPE_Tradetype1', 'ORGANIZATION_TYPE_Tradetype2', 'ORGANIZATION_TYPE_Tradetype3', 'ORGANIZATION_TYPE_Tradetype4', 'ORGANIZATION_TYPE_Tradetype5', 'ORGANIZATION_TYPE_Tradetype6', 'ORGANIZATION_TYPE_Tradetype7', 'ORGANIZATION_TYPE_Transporttype1', 'ORGANIZATION_TYPE_Transporttype2', 'ORGANIZATION_TYPE_Transporttype3', 'ORGANIZATION_TYPE_Transporttype4', 'ORGANIZATION_TYPE_University', 'ORGANIZATION_TYPE_XNA', 'FONDKAPREMONT_MODE_orgspecaccount', 'FONDKAPREMONT_MODE_regoperaccount', 'FONDKAPREMONT_MODE_regoperspecaccount', 'HOUSETYPE_MODE_specifichousing', 'HOUSETYPE_MODE_terracedhouse', 'WALLSMATERIAL_MODE_Mixed', 'WALLSMATERIAL_MODE_Monolithic', 'WALLSMATERIAL_MODE_Others', 'WALLSMATERIAL_MODE_Panel', 'WALLSMATERIAL_MODE_Stonebrick', 'WALLSMATERIAL_MODE_Wooden', 'EMERGENCYSTATE_MODE_Yes', 'CREDIT_ACTIVE_Closed', 'CREDIT_ACTIVE_Sold', 'CREDIT_CURRENCY_currency2', 'CREDIT_TYPE_Carloan', 'CREDIT_TYPE_Consumercredit', 'CREDIT_TYPE_Creditcard', 'CREDIT_TYPE_Loanforbusinessdevelopment', 'CREDIT_TYPE_Loanforthepurchaseofequipment', 'CREDIT_TYPE_Loanforworkingcapitalreplenishment', 'CREDIT_TYPE_Microloan', 'CREDIT_TYPE_Mortgage', 'CREDIT_TYPE_Unknowntypeofloan', 'STATUS_1', 'STATUS_2', 'STATUS_3', 'STATUS_4', 'STATUS_5', 'STATUS_C', 'STATUS_X'] ['SK_ID_CURR', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'SK_ID_BUREAU', 'DAYS_CREDIT', 'CREDIT_DAY_OVERDUE', 'DAYS_CREDIT_ENDDATE', 'DAYS_ENDDATE_FACT', 'AMT_CREDIT_MAX_OVERDUE', 'CNT_CREDIT_PROLONG', 'AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM_LIMIT', 'AMT_CREDIT_SUM_OVERDUE', 'DAYS_CREDIT_UPDATE', 'MONTHS_BALANCE', 'NAME_CONTRACT_TYPE_Revolvingloans', 'CODE_GENDER_M', 'FLAG_OWN_CAR_Y', 'FLAG_OWN_REALTY_Y', 'NAME_TYPE_SUITE_Family', 'NAME_TYPE_SUITE_Groupofpeople', 'NAME_TYPE_SUITE_Other_A', 'NAME_TYPE_SUITE_Other_B', 'NAME_TYPE_SUITE_Spousepartner', 'NAME_TYPE_SUITE_Unaccompanied', 'NAME_INCOME_TYPE_Commercialassociate', 'NAME_INCOME_TYPE_Pensioner', 'NAME_INCOME_TYPE_Stateservant', 'NAME_INCOME_TYPE_Student', 'NAME_INCOME_TYPE_Unemployed', 'NAME_INCOME_TYPE_Working', 'NAME_EDUCATION_TYPE_Highereducation', 'NAME_EDUCATION_TYPE_Incompletehigher', 'NAME_EDUCATION_TYPE_Lowersecondary', 'NAME_EDUCATION_TYPE_Secondarysecondaryspecial', 'NAME_FAMILY_STATUS_Married', 'NAME_FAMILY_STATUS_Separated', 'NAME_FAMILY_STATUS_Singlenotmarried', 'NAME_FAMILY_STATUS_Widow', 'NAME_HOUSING_TYPE_Houseapartment', 'NAME_HOUSING_TYPE_Municipalapartment', 'NAME_HOUSING_TYPE_Officeapartment', 'NAME_HOUSING_TYPE_Rentedapartment', 'NAME_HOUSING_TYPE_Withparents', 'OCCUPATION_TYPE_Cleaningstaff', 'OCCUPATION_TYPE_Cookingstaff', 'OCCUPATION_TYPE_Corestaff', 'OCCUPATION_TYPE_Drivers', 'OCCUPATION_TYPE_HRstaff', 'OCCUPATION_TYPE_Highskilltechstaff', 'OCCUPATION_TYPE_ITstaff', 'OCCUPATION_TYPE_Laborers', 'OCCUPATION_TYPE_LowskillLaborers', 'OCCUPATION_TYPE_Managers', 'OCCUPATION_TYPE_Medicinestaff', 'OCCUPATION_TYPE_Privateservicestaff', 'OCCUPATION_TYPE_Realtyagents', 'OCCUPATION_TYPE_Salesstaff', 'OCCUPATION_TYPE_Secretaries', 'OCCUPATION_TYPE_Securitystaff', 'OCCUPATION_TYPE_Waitersbarmenstaff', 'WEEKDAY_APPR_PROCESS_START_MONDAY', 'WEEKDAY_APPR_PROCESS_START_SATURDAY', 'WEEKDAY_APPR_PROCESS_START_SUNDAY', 'WEEKDAY_APPR_PROCESS_START_THURSDAY', 'WEEKDAY_APPR_PROCESS_START_TUESDAY', 'WEEKDAY_APPR_PROCESS_START_WEDNESDAY', 'ORGANIZATION_TYPE_Agriculture', 'ORGANIZATION_TYPE_Bank', 'ORGANIZATION_TYPE_BusinessEntityType1', 'ORGANIZATION_TYPE_BusinessEntityType2', 'ORGANIZATION_TYPE_BusinessEntityType3', 'ORGANIZATION_TYPE_Cleaning', 'ORGANIZATION_TYPE_Construction', 'ORGANIZATION_TYPE_Culture', 'ORGANIZATION_TYPE_Electricity', 'ORGANIZATION_TYPE_Emergency', 'ORGANIZATION_TYPE_Government', 'ORGANIZATION_TYPE_Hotel', 'ORGANIZATION_TYPE_Housing', 'ORGANIZATION_TYPE_Industrytype1', 'ORGANIZATION_TYPE_Industrytype10', 'ORGANIZATION_TYPE_Industrytype11', 'ORGANIZATION_TYPE_Industrytype12', 'ORGANIZATION_TYPE_Industrytype13', 'ORGANIZATION_TYPE_Industrytype2', 'ORGANIZATION_TYPE_Industrytype3', 'ORGANIZATION_TYPE_Industrytype4', 'ORGANIZATION_TYPE_Industrytype5', 'ORGANIZATION_TYPE_Industrytype6', 'ORGANIZATION_TYPE_Industrytype7', 'ORGANIZATION_TYPE_Industrytype8', 'ORGANIZATION_TYPE_Industrytype9', 'ORGANIZATION_TYPE_Insurance', 'ORGANIZATION_TYPE_Kindergarten', 'ORGANIZATION_TYPE_LegalServices', 'ORGANIZATION_TYPE_Medicine', 'ORGANIZATION_TYPE_Military', 'ORGANIZATION_TYPE_Mobile', 'ORGANIZATION_TYPE_Other', 'ORGANIZATION_TYPE_Police', 'ORGANIZATION_TYPE_Postal', 'ORGANIZATION_TYPE_Realtor', 'ORGANIZATION_TYPE_Religion', 'ORGANIZATION_TYPE_Restaurant', 'ORGANIZATION_TYPE_School', 'ORGANIZATION_TYPE_Security', 'ORGANIZATION_TYPE_SecurityMinistries', 'ORGANIZATION_TYPE_Selfemployed', 'ORGANIZATION_TYPE_Services', 'ORGANIZATION_TYPE_Telecom', 'ORGANIZATION_TYPE_Tradetype1', 'ORGANIZATION_TYPE_Tradetype2', 'ORGANIZATION_TYPE_Tradetype3', 'ORGANIZATION_TYPE_Tradetype4', 'ORGANIZATION_TYPE_Tradetype5', 'ORGANIZATION_TYPE_Tradetype6', 'ORGANIZATION_TYPE_Tradetype7', 'ORGANIZATION_TYPE_Transporttype1', 'ORGANIZATION_TYPE_Transporttype2', 'ORGANIZATION_TYPE_Transporttype3', 'ORGANIZATION_TYPE_Transporttype4', 'ORGANIZATION_TYPE_University', 'ORGANIZATION_TYPE_XNA', 'FONDKAPREMONT_MODE_orgspecaccount', 'FONDKAPREMONT_MODE_regoperaccount', 'FONDKAPREMONT_MODE_regoperspecaccount', 'HOUSETYPE_MODE_specifichousing', 'HOUSETYPE_MODE_terracedhouse', 'WALLSMATERIAL_MODE_Mixed', 'WALLSMATERIAL_MODE_Monolithic', 'WALLSMATERIAL_MODE_Others', 'WALLSMATERIAL_MODE_Panel', 'WALLSMATERIAL_MODE_Stonebrick', 'WALLSMATERIAL_MODE_Wooden', 'EMERGENCYSTATE_MODE_Yes', 'CREDIT_ACTIVE_Closed', 'CREDIT_ACTIVE_Sold', 'CREDIT_CURRENCY_currency2', 'CREDIT_CURRENCY_currency3', 'CREDIT_TYPE_Carloan', 'CREDIT_TYPE_Cashloannonearmarked', 'CREDIT_TYPE_Consumercredit', 'CREDIT_TYPE_Creditcard', 'CREDIT_TYPE_Loanforbusinessdevelopment', 'CREDIT_TYPE_Loanforworkingcapitalreplenishment', 'CREDIT_TYPE_Microloan', 'CREDIT_TYPE_Mortgage', 'CREDIT_TYPE_Unknowntypeofloan', 'STATUS_1', 'STATUS_2', 'STATUS_3', 'STATUS_4', 'STATUS_5', 'STATUS_C', 'STATUS_X']\nexpected CREDIT_TYPE_Loanforthepurchaseofequipment, NAME_FAMILY_STATUS_Unknown, NAME_INCOME_TYPE_Maternityleave in input data\ntraining data did not have the following fields: CREDIT_TYPE_Cashloannonearmarked, NAME_INCOME_TYPE_Unemployed, NAME_INCOME_TYPE_Commercialassociate, CREDIT_CURRENCY_currency3, ORGANIZATION_TYPE_Industrytype8"
     ]
    }
   ],
   "source": [
    "#Teste com o dataframe de Teste Global\n",
    "\n",
    "#Realizando o treinamento com base no X1\n",
    "estimador_df.fit(X1, y)\n",
    "#Realizando a predição com base no X1_teste\n",
    "preds_1_teste = estimador_df.predict(X1_test)\n",
    "\n",
    "#Realizando o treinamento com base no X2\n",
    "estimador_df.fit(X2, y)\n",
    "#Realizando a predição com base no X2_teste\n",
    "preds_2_teste = estimador_df.predict(X2_test)\n",
    "\n",
    "#Realizando o treinamento com base no X3\n",
    "estimador_df.fit(X3, y)\n",
    "#Realizando a predição com base no X3_teste\n",
    "preds_3_teste = estimador_df.predict(X3_test)\n",
    "\n",
    "#Realizando o treinamento com base no X4\n",
    "estimador_df.fit(X4, y)\n",
    "#Realizando a predição com base no X4_teste\n",
    "preds_4_teste = estimador_df.predict(X4_test)\n",
    "\n",
    "soma = preds_1_teste + preds_2_teste + preds_3_teste + preds_4_teste\n",
    "\n",
    "preds = [1 if s > 2 else 0 for s in soma]\n",
    "\n",
    "#Geração do Data Frame das predições com o Teste Global\n",
    "df_kaggle = df_test.copy()\n",
    "df_kaggle[\"TARGET\"] = preds\n",
    "\n",
    "# Salvar os CSVs\n",
    "df_kaggle[[\"SK_ID_CURR\", \"TARGET\"]].to_csv(\"df_kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQj6wTq_gEV8"
   },
   "source": [
    "#RESULTADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_q6D4BDhN9L"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4hJqW5NhN9L"
   },
   "source": [
    "Como informado anteriormente, devido a grande quantidade de dados e limitações estruturais e de capacidade do notebook não foi possível criar uma base única com as devidas mesclagens. Como alternativa, montou-se 4 Data Frames (df_01 a df_04) com join de bases diferentes, mas tento uma base principal. Mas como a base inicial ainda continuava grande, optou-se por amostrar em 20% a base original, aleatoriamente. Cada Data Frame, gerado aleatoriamente, foi utilizado para treinar modelos dos classificadores da prática (XGBOOST, LIGHTGBM e CATBOOST), tendo como métrica de avaliação o ROC-UAC.\n",
    "\n",
    "Para o df_01 obteve-se como resultados:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "Para o df_02 obteve-se como resultados:\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "\n",
    "Para o df_03 obteve-se como resultados:\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "\n",
    "Para o df_04 obteve-se como resultados:\n",
    "\n",
    "![image-4.png](attachment:image-4.png)\n",
    "\n",
    "\n",
    "Observou-se que os modelos que sairam melhor foram o XGBOOST, LIGHTGBM, ambos com resultados próximos. Já o CATBOOST foi o de pior resultado em todos os dataframes.\n",
    "\n",
    "No intuito de agregar os diferentes modelos para uma melhor resposta, utilizou-se a estratégia a combinação com VotingClassifier (Hard e Soft) e StackingClassifier. A combinação consiste na combinação de modelos, gerando um novo modelo, e com este novo modelo há o treinamento de uma base. Como nossa base não foi única, e sim fragmentada nos 4 data frames, optou-se por escolher o df_01 como base para X e y na combinação. A escolha foi feita por entendermos que o df_01 trazia mais informações, no entanto, ficamos com dúvida se está é uma boa e ideal escolha.\n",
    "\n",
    "Para o VotingClassifier (Hard e Soft) obteve-se os seguintes resultados:\n",
    "\n",
    "![image-5.png](attachment:image-5.png)\n",
    "\n",
    "![image-7.png](attachment:image-7.png)\n",
    "\n",
    "Para o StackingClassifier obteve-se os seguinte resultado\n",
    "\n",
    "![image-6.png](attachment:image-6.png)\n",
    "\n",
    "Para ambos os modelos gerados através da combinação houve a predição com o dataframe de test do Kaggle. Gerou-se 2 arquivos . CSV que foram submetidos no Kaggle, obtendo-se os seguintes resultados:\n",
    "\n",
    "![image-8.png](attachment:image-8.png)\n",
    "\n",
    "Em comparação com as simulações individuais  observou-se que houve a piora pela combinação do modelos. No entanto, os resultados da combinação foram mais próximos dos resultados após submissão no Kaggle. Isto sugere que os modelos individuais estão mais overfitados. No entanto, tem-se que ponderar que somente 20% de dados ( aproximadamente 66 mil) foram utilizados.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LhNgHgeP5bY5",
    "OIc6Rllz40KD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
