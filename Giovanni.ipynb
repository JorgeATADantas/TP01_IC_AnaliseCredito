{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QYddtZjGH_s"
   },
   "source": [
    "**Tabalho Prático 1 – Análise de Crédito**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghA_ViPQGH3r"
   },
   "source": [
    "**Alunos:\n",
    "\n",
    "GIOVANNI SURIANI FERREIRA\n",
    "\n",
    "JORGE ALIOMAR TROCOLI ABDON DANTAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFr8QeByGHqO"
   },
   "source": [
    "**Enunciado(s):**\n",
    "\n",
    "Cada dupla deve escolher um problema no Kaggle. Elaborar uma solução e apresentar para turma no dia da entrega. A solução da dupla deve ser entregue no Moodle em um Python Notebook. Especificamente, a dupla deve:\n",
    "- Pesquisar um problema interessante no Kaggle que envolva dados tabulares/estruturados;\n",
    "- Realizar uma análise exploratória dos dados da competição. Isto é, visualizar os dados, tentar identificar dados faltantes, instâncias ruidosas e tendências nos dados;\n",
    "- Entender e implementar a métrica de avaliação da competição;\n",
    "- Implementar uma solução simples para o problema da competição para gerar um baseline (isto é, o desempenho mínimo que o sua abordagem deve alcançar);\n",
    "- Estudar soluções para problemas semelhantes ao da competição escolhida. A dupla pode pesquisar, por exemplo, em artigos acadêmicos, artigos técnicos da Internet e o no próprio Kaggle;\n",
    "- Implementar diferentes abordagens para a competição e reportar o desempenho de cada abordagem implementada;\n",
    "- Realizar uma avaliação de parâmetro (hyperparameter tuning) das abordagens escolhidas para o problema. Para realizar a avaliação dos parâmetros você pode utilizar GridSearchCV ou Optuna.\n",
    "- Além de outras abordagens, a dupla deve:\n",
    "    - Propor pelo menos uma abordagem que envolva meta-learning. Ou seja, a dupla deve propor uma forma diferente de combinar vários modelos. Por exemplo, utilize a abordagem do Random Forest, porém com vários classificadores ou invés de utilizar apenas Árvores de Decisão.\n",
    "- Para cada abordagem apresentada, a dupla deve apresentar:\n",
    "    - desempenho no conjunto de treino, o desempenho deve ser medido com uma validação cruzada com 10 folds (10-fold cross-validation).\n",
    "    - desempenho no conjunto de teste reportado pelo Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_eehgWhhN8g"
   },
   "source": [
    "# DESAFIO E PROBLEMA ESCOLHIDO\n",
    "Home Credit Default Risk (https://www.kaggle.com/competitions/home-credit-default-risk)\n",
    "\n",
    "O desafio consiste em melhorar os modelos preditivos, da HOME CREDIT, de crédito voltados a pessoas sem histórico bancário. Utilizando dados alternativos como registros de telecomunicações e transações, a empresa quer garantir que mais pessoas aptas recebam empréstimos justos e sustentáveis. O desafio propõe que os participantes usem técnicas de ciência de dados e machine learning para prever com mais precisão a capacidade de pagamento dos clientes.\n",
    "\n",
    "O conjunto de dados contém informações detalhadas sobre o histórico financeiro de clientes da Home Credit e de outras instituições, com o objetivo de prever a capacidade de pagamento de novos empréstimos.\n",
    "\n",
    " - application_{train|test}.csv: Esta é a tabela principal, dividida em dois arquivos: Treinamento (com a variável TARGET) e Teste (sem TARGET). Contém dados estáticos de todas as solicitações de empréstimo. Cada linha representa um empréstimo.\n",
    "\n",
    " - bureau.csv: Todos os créditos anteriores dos clientes fornecidos por outras instituições financeiras, reportados ao Bureau de Crédito (apenas para clientes com empréstimo na amostra). Cada linha representa um crédito anterior registrado antes da data da aplicação atual.\n",
    "\n",
    " - bureau_balance.csv: Saldos mensais dos créditos anteriores no Bureau de Crédito. Cada linha representa um mês de histórico para cada crédito anterior — ou seja, número de empréstimos * número de créditos anteriores * número de meses com histórico disponível.\n",
    "\n",
    " - POS_CASH_balance.csv: Saldos mensais dos empréstimos anteriores no ponto de venda (POS) ou empréstimos em dinheiro que o cliente teve com a Home Credit. Uma linha por mês de histórico de cada crédito anterior relacionado ao empréstimo na amostra.\n",
    "\n",
    " - credit_card_balance.csv: Saldos mensais dos cartões de crédito anteriores que o cliente tem com a Home Credit. Formato similar ao POS_CASH_balance, mas para cartões de crédito.\n",
    "\n",
    " - previous_application.csv: Todas as solicitações anteriores de empréstimos feitas à Home Credit por clientes com empréstimos na amostra atual. Uma linha por solicitação anterior.\n",
    "\n",
    " - installments_payments.csv: Histórico de pagamentos de créditos anteriores concedidos pela Home Credit. Inclui: a) uma linha para cada pagamento feito, e b) uma linha para cada parcela não paga. Cada linha representa um pagamento ou uma parcela de um crédito anterior.\n",
    "\n",
    " - HomeCredit_columns_description.csv: Arquivo com a descrição das colunas de todos os outros arquivos do conjunto de dados.\n",
    "\n",
    " As tabelas podem se relacionar conforme imagem abaixo:\n",
    "\n",
    " ![image.png](attachment:image.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzZ2MAv0hN8i"
   },
   "source": [
    "# PREPARAÇÃO DA BASE DE DADOS - Todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G3ZCBI41MkU5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "#Importando Bibliotecas Pandas e Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "\n",
    "#Otimizador Giovanni\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "\n",
    "CSV_PATH = \"/home/gi/Desktop/Semestre8/Inteligencia_Computacional/TP1_csvs\" # Path Giovanni\n",
    "# CSV_PATH = \"E:/Documentos/CEFET/OneDrive/Documentos/2ECOM067_INTELIGENCIA-COMPUTACIONAL-I_T01/TP1/bases/\" # Path Jorge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pGvW8rR6hN8m"
   },
   "outputs": [],
   "source": [
    "#Desabilitando os warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "232RQBEu3mWD"
   },
   "outputs": [],
   "source": [
    "#Carregando Base de dados principal - Treino\n",
    "df_train = pd.read_csv(f\"{CSV_PATH}/application_train.csv\")\n",
    "df_01 = pd.read_csv(f\"{CSV_PATH}/df_01.csv\")\n",
    "df_02 = pd.read_csv(f\"{CSV_PATH}/df_02.csv\")\n",
    "df_03 = pd.read_csv(f\"{CSV_PATH}/df_03.csv\")\n",
    "df_04 = pd.read_csv(f\"{CSV_PATH}/df_04.csv\")\n",
    "\n",
    "y_train = df_train['TARGET']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.info(max_cols=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJjJF_XGhN8u"
   },
   "source": [
    "# PREPARAÇÃO DA BASE DE DADOS - Amostra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gI6kKG4ghN8v"
   },
   "source": [
    "Como as bases de dados original tem muitos valores, e as simulações subsequentes podem demorar muitas horas, realizar-se-a uma amostra aleatória das bases para treinamento e teste.\n",
    "Para deixar as bases com os mesmos SK_ID_CURR, faz-se primeiramente a amostragem via df_01, e para os demais dataframes selecionamos os valores dos atributos (colunas) do SK_ID_CURR do df_01. Isso faz com que o y_train seja único para os 4 df_x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_xtrain_ytrain(df_01, df_02, df_03, df_04):\n",
    "    df_01_train = df_01.sample(frac=0.1, random_state=42)  # Seleciona 10% do DataFrame\n",
    "    df_02_train = df_02.sample(frac=0.1, random_state=42)  # Seleciona 10% do DataFrame\n",
    "    df_03_train = df_03.sample(frac=0.1, random_state=42)  # Seleciona 10% do DataFrame\n",
    "    df_04_train = df_04.sample(frac=0.1, random_state=42)  # Seleciona 10% do DataFrame\n",
    "\n",
    "    #Divisão treino\n",
    "    X_train_df_01 = df_01_train.drop(columns={\"TARGET\"})\n",
    "    y_train_df_01 = df_01_train[\"TARGET\"]\n",
    "    X_train_df_02 = df_02_train.drop(columns={\"TARGET\"})\n",
    "    y_train_df_02 = df_02_train[\"TARGET\"]\n",
    "    X_train_df_03 = df_03_train.drop(columns={\"TARGET\"})\n",
    "    y_train_df_03 = df_03_train[\"TARGET\"]\n",
    "    X_train_df_04 = df_04_train.drop(columns={\"TARGET\"})\n",
    "    y_train_df_04 = df_04_train[\"TARGET\"]\n",
    "    return  X_train_df_01, y_train_df_01, X_train_df_02, y_train_df_02, X_train_df_03, y_train_df_03, X_train_df_04, y_train_df_04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "42r9hUZuhN8v"
   },
   "outputs": [],
   "source": [
    "#Amostra df_01_train\n",
    "df_01_train = df_01.sample(frac=0.1, random_state=42)  # Seleciona 10% do DataFrame\n",
    "\n",
    "\n",
    "#Divisão treino\n",
    "X_train_df_01 = df_01_train.drop(columns={\"TARGET\"})\n",
    "y_train_df_01 = df_01_train[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6uN3N9GhN8x"
   },
   "source": [
    "# 1. Treinamento Individual dos Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ToKRgzDvhN8x"
   },
   "outputs": [],
   "source": [
    "#Importanto as Bibliotecas dos classificadores\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Importando biblioteca de clone\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Importando stratified k-fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o desempenho dos classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test shape (307511, 122), df_01 shape (30751, 140), df_02 shape (30751, 165), df_03 shape (30751, 165), df_04 shape (30751, 180)\n"
     ]
    }
   ],
   "source": [
    "import four_dataframes_from1 as fd\n",
    "df_train = pd.read_csv(f\"{CSV_PATH}/application_train.csv\")\n",
    "df_01, df_02, df_03, df_04 = fd.four_dataframes_from_one(df_train, sample=0.1)\n",
    "y_train = df_01[\"TARGET\"]\n",
    "x_1 = df_01.drop(columns={\"TARGET\"})\n",
    "x_2 = df_02.drop(columns={\"TARGET\"})\n",
    "x_3 = df_03.drop(columns={\"TARGET\"})\n",
    "x_4 = df_04.drop(columns={\"TARGET\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dataframes possuem a mesma coluna TARGET\n"
     ]
    }
   ],
   "source": [
    "# Confirmando que todos os targets sao os mesmos\n",
    "if df_01[\"TARGET\"].equals(df_02[\"TARGET\"]) and df_01[\"TARGET\"].equals(df_03[\"TARGET\"]) and df_01[\"TARGET\"].equals(df_04[\"TARGET\"]):\n",
    "    print(\"Os dataframes possuem a mesma coluna TARGET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição 1:  roc_auc = 0.6977\n",
      "Predição 1:  roc_auc = 0.7077\n",
      "Predição 1:  roc_auc = 0.6897\n",
      "Predição 1:  roc_auc = 0.7231\n",
      "Predição 1:  roc_auc = 0.6893\n",
      "Predição 1:  roc_auc = 0.6898\n",
      "Predição 1:  roc_auc = 0.6961\n",
      "Predição 1:  roc_auc = 0.7270\n",
      "Predição 1:  roc_auc = 0.7154\n",
      "Predição 1:  roc_auc = 0.6874\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "# Verificando so com o primeiro df\n",
    "for train_index, test_index in skf.split(x_1, y_train):\n",
    "    # Divide os dados de teste\n",
    "    y_test_fold = y_train.iloc[test_index]\n",
    "    x_1_test = x_1.iloc[test_index]\n",
    "    xgb.fit(x_1.iloc[train_index], y_train.iloc[train_index])\n",
    "    # Predições de classe (0 ou 1)\n",
    "    xgb_pred_proba = xgb.predict_proba(x_1_test)[:, 1]  # Probabilidade da classe 1\n",
    "    roc_auc = roc_auc_score(y_test_fold, xgb_pred_proba)\n",
    "    print(f\"Predição 1:  roc_auc = {roc_auc:.4f}\")\n",
    "\n",
    "    # AUC para predições finais\n",
    "    # roc_auc = roc_auc_score(y_test_fold, pred_final)\n",
    "    # roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    # Cada modelo usa um X diferente para prever\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "def avaliar_modelo_meta_individual(model, X_1, X_2, X_3, X_4, y_train, nome):\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X_1, y_train):\n",
    "        # Divide os dados de teste\n",
    "        y_test_fold = y_train.iloc[test_index]\n",
    "\n",
    "        # Dados de teste para cada modelo\n",
    "        X1_test = X_1.iloc[test_index]\n",
    "        X2_test = X_2.iloc[test_index]\n",
    "        X3_test = X_3.iloc[test_index]\n",
    "        X4_test = X_4.iloc[test_index]\n",
    "\n",
    "        # Clona e treina os modelos em seus respectivos datasets\n",
    "        m1 = clone(model).fit(X_1.iloc[train_index], y_train.iloc[train_index])\n",
    "        m2 = clone(model).fit(X_2.iloc[train_index], y_train.iloc[train_index])\n",
    "        m3 = clone(model).fit(X_3.iloc[train_index], y_train.iloc[train_index])\n",
    "        m4 = clone(model).fit(X_4.iloc[train_index], y_train.iloc[train_index])\n",
    "\n",
    "        # Obtém as probabilidades da classe positiva\n",
    "        p1 = (m1.predict_proba(X1_test)[:, 1] >= 0.5).astype(int)\n",
    "        p2 = (m2.predict_proba(X2_test)[:, 1] >= 0.5).astype(int)\n",
    "        p3 = (m3.predict_proba(X3_test)[:, 1] >= 0.5).astype(int)\n",
    "        p4 = (m4.predict_proba(X4_test)[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "        # Avaliação individual opcional\n",
    "        print(f\"Predição 1:  accuracy_auc = {accuracy_score(y_test_fold, p1):.4f}\")\n",
    "        print(f\"Predição 2:  accuracy_auc = {accuracy_score(y_test_fold, p2):.4f}\")\n",
    "        print(f\"Predição 3:  accuracy_auc = {accuracy_score(y_test_fold, p3):.4f}\")\n",
    "        print(f\"Predição 4:  accuracy_auc = {accuracy_score(y_test_fold, p4):.4f}\")   \n",
    "\n",
    "        # Ensemble: \n",
    "        preds = np.column_stack([p1, p2, p3, p4])\n",
    "        print(f\"{preds}\")\n",
    "        pred_final = (preds.sum(axis=1) >= 2).astype(int)\n",
    "\n",
    "        # Avaliação do ensemble\n",
    "        roc_auc = roc_auc_score(y_test_fold, pred_final)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test_fold, pred_final)\n",
    "        f1 = f1_score(y_test_fold, pred_final)\n",
    "    print(f\"Predição final:  accuracy_auc = {accuracy:.4f}\")\n",
    "    print(f\"Predição final:  f1_auc = {f1:.4f}\")\n",
    "    #print(f\"{nome}: roc_auc_mean = {np.mean(roc_auc_scores):.4f}, desvio padrão = {np.std(roc_auc_scores):.4f}\")\n",
    "    return np.mean(roc_auc_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição 1:  accuracy_auc = 0.9125\n",
      "Predição 2:  accuracy_auc = 0.9158\n",
      "Predição 3:  accuracy_auc = 0.9161\n",
      "Predição 4:  accuracy_auc = 0.9161\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Predição 1:  accuracy_auc = 0.9138\n",
      "Predição 2:  accuracy_auc = 0.9148\n",
      "Predição 3:  accuracy_auc = 0.9164\n",
      "Predição 4:  accuracy_auc = 0.9141\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Predição 1:  accuracy_auc = 0.9148\n",
      "Predição 2:  accuracy_auc = 0.9128\n",
      "Predição 3:  accuracy_auc = 0.9145\n",
      "Predição 4:  accuracy_auc = 0.9099\n",
      "[[0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Predição 1:  accuracy_auc = 0.9187\n",
      "Predição 2:  accuracy_auc = 0.9138\n",
      "Predição 3:  accuracy_auc = 0.9148\n",
      "Predição 4:  accuracy_auc = 0.9145\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Predição 1:  accuracy_auc = 0.9161\n",
      "Predição 2:  accuracy_auc = 0.9138\n",
      "Predição 3:  accuracy_auc = 0.9161\n",
      "Predição 4:  accuracy_auc = 0.9148\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Predição 1:  accuracy_auc = 0.9102\n",
      "Predição 2:  accuracy_auc = 0.9138\n",
      "Predição 3:  accuracy_auc = 0.9132\n",
      "Predição 4:  accuracy_auc = 0.9138\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Predição 1:  accuracy_auc = 0.9145\n",
      "Predição 2:  accuracy_auc = 0.9119\n",
      "Predição 3:  accuracy_auc = 0.9148\n",
      "Predição 4:  accuracy_auc = 0.9138\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Predição 1:  accuracy_auc = 0.9122\n",
      "Predição 2:  accuracy_auc = 0.9125\n",
      "Predição 3:  accuracy_auc = 0.9161\n",
      "Predição 4:  accuracy_auc = 0.9184\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 1 0 0]]\n",
      "Predição 1:  accuracy_auc = 0.9122\n",
      "Predição 2:  accuracy_auc = 0.9148\n",
      "Predição 3:  accuracy_auc = 0.9161\n",
      "Predição 4:  accuracy_auc = 0.9167\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Predição 1:  accuracy_auc = 0.9145\n",
      "Predição 2:  accuracy_auc = 0.9164\n",
      "Predição 3:  accuracy_auc = 0.9154\n",
      "Predição 4:  accuracy_auc = 0.9164\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Predição final:  accuracy_auc = 0.9177\n",
      "Predição final:  f1_auc = 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5226711999245983)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliar_modelo_meta_individual(XGBClassifier(), x_1, x_2, x_3, x_4, y_train, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 1\n",
      "XGBClassifier1: roc_auc = 0.7044, desvio padrão = 0.0000\n",
      "Modelo 2\n",
      "XGBClassifier2: roc_auc = 0.7023, desvio padrão = 0.0000\n",
      "Modelo 3\n",
      "XGBClassifier3: roc_auc = 0.7057, desvio padrão = 0.0000\n",
      "Modelo 4\n",
      "XGBClassifier4: roc_auc = 0.7036, desvio padrão = 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "lgbm = LGBMClassifier(\n",
    "    random_state=42,\n",
    ")\n",
    "catboosta = CatBoostClassifier(\n",
    "    random_state=42,\n",
    "    verbose=0,  # Desativa a saída de log do CatBoost\n",
    ")\n",
    "X_train_df_01, y_train_df_01, X_train_df_02, y_train_df_02, X_train_df_03, y_train_df_03, X_train_df_04, y_train_df_04 = generate_all_xtrain_ytrain(df_01, df_02, df_03, df_04)\n",
    "\n",
    "X_trains = [X_train_df_01, X_train_df_02, X_train_df_03, X_train_df_04]\n",
    "y_trains = [y_train_df_01, y_train_df_02, y_train_df_03, y_train_df_04]\n",
    "\n",
    "xgb1 = clone(xgb).fit(X_train_df_01, y_train_df_01)\n",
    "xgb2 = clone(xgb).fit(X_train_df_02, y_train_df_02)\n",
    "xgb3 = clone(xgb).fit(X_train_df_03, y_train_df_03)\n",
    "xgb4 = clone(xgb).fit(X_train_df_04, y_train_df_04)\n",
    "\n",
    "for i, (X_train, y_train) in enumerate(zip(X_trains, y_trains)):\n",
    "    print(f\"Modelo {i+1}\")\n",
    "    # Avaliando o modelo XGBClassifier\n",
    "    avaliar_modelo_individual(xgb, X_train, y_train, f\"XGBClassifier{i+1}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando os modelos individuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = clone(xgb).fit(X_train_df_01, y_train_df_01)\n",
    "xgb2 = clone(xgb).fit(X_train_df_02, y_train_df_02)\n",
    "xgb3 = clone(xgb).fit(X_train_df_03, y_train_df_03)\n",
    "xgb4 = clone(xgb).fit(X_train_df_04, y_train_df_04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTwB2Ho2hN9H"
   },
   "source": [
    "# 2. Combinação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njVl8rfAhN9H"
   },
   "source": [
    "Pegou-se os modelos com melhores resultados dos dataframes df_01, df_02, df_03 e df_04 e aplicou a estratégia de combinação deles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "mVKbgZvXhN9H"
   },
   "outputs": [],
   "source": [
    "#Importando Bibliotecas pertinentes\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Suponha que X_meta e y_meta sejam os dados que TODOS os modelos podem prever\n",
    "# Pode ser um subconjunto comum ou seu conjunto de teste\n",
    "\n",
    "def avaliar_modelo_final(X1, X2, X3, X4, Y, nome):\n",
    "    roc_auc_scores = []\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = Y.iloc[test_index]\n",
    "         # Predições de classe (0 ou 1)\n",
    "        pred1 = xgb1.predict(X_test_fold)\n",
    "        pred2 = xgb2.predict(X_test_fold)\n",
    "        pred3 = xgb3.predict(X_test_fold)\n",
    "        pred4 = xgb4.predict(X_test_fold)\n",
    "         # Stack horizontalmente: shape (n amostras, 4 modelos)\n",
    "        preds = np.column_stack([pred1, pred2, pred3, pred4])\n",
    "        pred_final = (preds.sum(axis=1) >= 2).astype(int)\n",
    "        # Calcule a pontuação ROC AUC\n",
    "        roc_auc = roc_auc_score(y_test_fold, pred_final)\n",
    "        # ROC AUC\n",
    "        roc_auc = roc_auc_score(y_test_fold, pred_final)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "    print(f\"{nome}: ROC AUC mean = {np.mean(roc_auc_scores):.4f}, desvio padrão = {np.std(roc_auc_scores):.4f}\")\n",
    "    return np.mean(roc_auc_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste com o dataframe de Teste Global\n",
    "\n",
    "#Realizando o treinamento com base no X1\n",
    "estimador_df.fit(X1, y)\n",
    "#Realizando a predição com base no X1_teste\n",
    "preds_1_teste = estimador_df.predict(X1_test)\n",
    "\n",
    "#Realizando o treinamento com base no X2\n",
    "estimador_df.fit(X2, y)\n",
    "#Realizando a predição com base no X2_teste\n",
    "preds_2_teste = estimador_df.predict(X2_test)\n",
    "\n",
    "#Realizando o treinamento com base no X3\n",
    "estimador_df.fit(X3, y)\n",
    "#Realizando a predição com base no X3_teste\n",
    "preds_3_teste = estimador_df.predict(X3_test)\n",
    "\n",
    "#Realizando o treinamento com base no X4\n",
    "estimador_df.fit(X4, y)\n",
    "#Realizando a predição com base no X4_teste\n",
    "preds_4_teste = estimador_df.predict(X4_test)\n",
    "\n",
    "soma = preds_1_teste + preds_2_teste + preds_3_teste + preds_4_teste\n",
    "\n",
    "preds = [1 if s > 2 else 0 for s in soma]\n",
    "\n",
    "#Geração do Data Frame das predições com o Teste Global\n",
    "df_kaggle = df_test.copy()\n",
    "df_kaggle[\"TARGET\"] = preds\n",
    "\n",
    "# Salvar os CSVs\n",
    "df_kaggle[[\"SK_ID_CURR\", \"TARGET\"]].to_csv(\"df_kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQj6wTq_gEV8"
   },
   "source": [
    "#RESULTADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_q6D4BDhN9L"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4hJqW5NhN9L"
   },
   "source": [
    "Como informado anteriormente, devido a grande quantidade de dados e limitações estruturais e de capacidade do notebook não foi possível criar uma base única com as devidas mesclagens. Como alternativa, montou-se 4 Data Frames (df_01 a df_04) com join de bases diferentes, mas tento uma base principal. Mas como a base inicial ainda continuava grande, optou-se por amostrar em 20% a base original, aleatoriamente. Cada Data Frame, gerado aleatoriamente, foi utilizado para treinar modelos dos classificadores da prática (XGBOOST, LIGHTGBM e CATBOOST), tendo como métrica de avaliação o ROC-UAC.\n",
    "\n",
    "Para o df_01 obteve-se como resultados:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "Para o df_02 obteve-se como resultados:\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "\n",
    "Para o df_03 obteve-se como resultados:\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "\n",
    "Para o df_04 obteve-se como resultados:\n",
    "\n",
    "![image-4.png](attachment:image-4.png)\n",
    "\n",
    "\n",
    "Observou-se que os modelos que sairam melhor foram o XGBOOST, LIGHTGBM, ambos com resultados próximos. Já o CATBOOST foi o de pior resultado em todos os dataframes.\n",
    "\n",
    "No intuito de agregar os diferentes modelos para uma melhor resposta, utilizou-se a estratégia a combinação com VotingClassifier (Hard e Soft) e StackingClassifier. A combinação consiste na combinação de modelos, gerando um novo modelo, e com este novo modelo há o treinamento de uma base. Como nossa base não foi única, e sim fragmentada nos 4 data frames, optou-se por escolher o df_01 como base para X e y na combinação. A escolha foi feita por entendermos que o df_01 trazia mais informações, no entanto, ficamos com dúvida se está é uma boa e ideal escolha.\n",
    "\n",
    "Para o VotingClassifier (Hard e Soft) obteve-se os seguintes resultados:\n",
    "\n",
    "![image-5.png](attachment:image-5.png)\n",
    "\n",
    "![image-7.png](attachment:image-7.png)\n",
    "\n",
    "Para o StackingClassifier obteve-se os seguinte resultado\n",
    "\n",
    "![image-6.png](attachment:image-6.png)\n",
    "\n",
    "Para ambos os modelos gerados através da combinação houve a predição com o dataframe de test do Kaggle. Gerou-se 2 arquivos . CSV que foram submetidos no Kaggle, obtendo-se os seguintes resultados:\n",
    "\n",
    "![image-8.png](attachment:image-8.png)\n",
    "\n",
    "Em comparação com as simulações individuais  observou-se que houve a piora pela combinação do modelos. No entanto, os resultados da combinação foram mais próximos dos resultados após submissão no Kaggle. Isto sugere que os modelos individuais estão mais overfitados. No entanto, tem-se que ponderar que somente 20% de dados ( aproximadamente 66 mil) foram utilizados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizar label encoder"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LhNgHgeP5bY5",
    "OIc6Rllz40KD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
